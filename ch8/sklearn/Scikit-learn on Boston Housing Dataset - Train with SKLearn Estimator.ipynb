{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn.linear_model\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m LinearRegression\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn.model_selection\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m train_test_split\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn.metrics\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m mean_squared_error, r2_score\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjoblib\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m, \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m'\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "        \n",
      "    parser = argparse.ArgumentParser()\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--normalize\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mbool\u001b[39;49;00m, default=\u001b[36mFalse\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--test-size\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m, default=\u001b[34m0.1\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--random-state\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m123\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--model-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--training\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAINING\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "    \n",
      "    args, _ = parser.parse_known_args()\n",
      "    normalize = args.normalize\n",
      "    test_size = args.test_size\n",
      "    random_state = args.random_state\n",
      "    model_dir  = args.model_dir\n",
      "    training_dir = args.training\n",
      "\n",
      "    filename = os.path.join(training_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mhousing.csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    data = pd.read_csv(filename, delim_whitespace=\u001b[36mTrue\u001b[39;49;00m)\n",
      "    labels = data[[\u001b[33m'\u001b[39;49;00m\u001b[33mmedv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]]\n",
      "    samples = data.drop([\u001b[33m'\u001b[39;49;00m\u001b[33mmedv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], axis=\u001b[34m1\u001b[39;49;00m)\n",
      "    X_train, X_test, y_train, y_test = train_test_split(samples, labels, \n",
      "                                                        test_size=test_size, random_state=random_state)\n",
      "    regr = LinearRegression(normalize=normalize)\n",
      "    regr.fit(X_train, y_train)\n",
      "    y_pred = regr.predict(X_test)\n",
      "    \u001b[34mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mMean squared error: \u001b[39;49;00m\u001b[33m%.2f\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m % mean_squared_error(y_test, y_pred))\n",
      "    \u001b[34mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mCoefficient of determination: \u001b[39;49;00m\u001b[33m%.2f\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m % r2_score(y_test, y_pred))\n",
      "    \n",
      "    model = os.path.join(model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mmodel.joblib\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    joblib.dump(regr, model)\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "pygmentize sklearn-boston-housing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mFROM\u001b[39;49;00m\u001b[33m python:3.7\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mRUN\u001b[39;49;00m pip3 install --no-cache scikit-learn numpy pandas joblib sagemaker-training \n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "pygmentize Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "An error occurred (RepositoryAlreadyExistsException) when calling the CreateRepository operation: The repository with name 'sklearn-custom' already exists in the registry with id '613904931467'\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "aws ecr create-repository --repository-name sklearn-custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "export REGION=eu-west-1\n",
    "export ACCOUNT_ID=`aws sts get-caller-identity --query Account --output text`\n",
    "docker build -t sklearn-custom:sklearn -f Dockerfile .\n",
    "export IMAGE_ID=`docker images -q sklearn-custom:sklearn`\n",
    "docker tag $IMAGE_ID $ACCOUNT_ID.dkr.ecr.$REGION.amazonaws.com/sklearn-custom:sklearn\n",
    "aws ecr get-login-password | docker login --username AWS --password-stdin $ACCOUNT_ID.dkr.ecr.$REGION.amazonaws.com/sklearn-custom:latest\n",
    "docker push $ACCOUNT_ID.dkr.ecr.$REGION.amazonaws.com/sklearn-custom:sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.sklearn import SKLearn\n",
    "\n",
    "session = sagemaker.Session()\n",
    "account_id = session.boto_session.client('sts').get_caller_identity()['Account']\n",
    "region = session.boto_session.region_name\n",
    "\n",
    "training = 'file://.'\n",
    "output = 'file://.'\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "sk = SKLearn(entry_point='sklearn-boston-housing.py',\n",
    "             image_name=account_id+'.dkr.ecr.'+region+'.amazonaws.com/sklearn-custom:sklearn',\n",
    "             role=role,\n",
    "             train_instance_count=1, \n",
    "             train_instance_type='local',\n",
    "             output_path=output,\n",
    "             hyperparameters={\n",
    "                  'normalize': True,\n",
    "                  'test-size': 0.1\n",
    "              }\n",
    ")\n",
    "\n",
    "sk.fit({'training':training})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- ec2-user/ec2-user 802 2020-05-19 08:16 model.joblib\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "tar tvfz model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
