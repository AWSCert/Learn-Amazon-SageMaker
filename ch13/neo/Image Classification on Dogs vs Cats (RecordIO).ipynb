{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "session = sagemaker.Session()\n",
    "bucket = session.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-613904931467/dogscats/input/train/\n",
      "s3://sagemaker-us-east-1-613904931467/dogscats/input/validation/\n",
      "s3://sagemaker-us-east-1-613904931467/dogscats/output/\n"
     ]
    }
   ],
   "source": [
    "prefix = 'dogscats'\n",
    "s3_train_path = 's3://{}/{}/input/train/'.format(bucket, prefix)\n",
    "s3_val_path   = 's3://{}/{}/input/validation/'.format(bucket, prefix)\n",
    "s3_output     = 's3://{}/{}/output/'.format(bucket, prefix)\n",
    "\n",
    "print(s3_train_path)\n",
    "print(s3_val_path)\n",
    "print(s3_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the name of the image classification algorithm in our region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'get_image_uri' method will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "811284229777.dkr.ecr.us-east-1.amazonaws.com/image-classification:latest\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "region_name = boto3.Session().region_name\n",
    "container = get_image_uri(region_name, \"image-classification\", \"latest\")\n",
    "print(container)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "ic = sagemaker.estimator.Estimator(container,\n",
    "                                   role, \n",
    "                                   train_instance_count=1, \n",
    "                                   train_instance_type='ml.p3.2xlarge',\n",
    "                                   output_path=s3_output,\n",
    "                                   sagemaker_session=session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set algorithm parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#precision_dtype = 'float16'\n",
    "precision_dtype = 'float32'\n",
    "\n",
    "ic.set_hyperparameters(num_layers=50,               # Train a Resnet-50 model\n",
    "                       use_pretrained_model=0,      # Train from scratch\n",
    "                       num_classes=2,               # Dogs and cats\n",
    "                       num_training_samples=22500,  # Number of training samples\n",
    "                       mini_batch_size=128,\n",
    "                       precision_dtype=precision_dtype,\n",
    "                       epochs=30)                   # Learn the training samples 30 times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set dataset parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker:'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "WARNING:sagemaker:'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "train_data = sagemaker.session.s3_input(s3_train_path, \n",
    "                                        distribution='FullyReplicated', \n",
    "                                        content_type='application/x-recordio',\n",
    "                                        s3_data_type='S3Prefix')\n",
    "\n",
    "validation_data = sagemaker.session.s3_input(s3_val_path,\n",
    "                                             distribution='FullyReplicated', \n",
    "                                             content_type='application/x-recordio', \n",
    "                                             s3_data_type='S3Prefix')\n",
    "\n",
    "s3_channels = {'train': train_data, 'validation': validation_data}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-01 12:56:06 Starting - Starting the training job...\n",
      "2020-07-01 12:56:08 Starting - Launching requested ML instances......\n",
      "2020-07-01 12:57:26 Starting - Preparing the instances for training.........\n",
      "2020-07-01 12:58:44 Downloading - Downloading input data...\n",
      "2020-07-01 12:59:14 Training - Downloading the training image.\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34m[07/01/2020 12:59:42 INFO 140326804956992] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/image_classification/default-input.json: {u'beta_1': 0.9, u'gamma': 0.9, u'beta_2': 0.999, u'optimizer': u'sgd', u'use_pretrained_model': 0, u'eps': 1e-08, u'epochs': 30, u'lr_scheduler_factor': 0.1, u'num_layers': 152, u'image_shape': u'3,224,224', u'precision_dtype': u'float32', u'mini_batch_size': 32, u'weight_decay': 0.0001, u'learning_rate': 0.1, u'momentum': 0}\u001b[0m\n",
      "\u001b[34m[07/01/2020 12:59:42 INFO 140326804956992] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {u'use_pretrained_model': u'0', u'epochs': u'30', u'num_training_samples': u'22500', u'num_layers': u'50', u'mini_batch_size': u'128', u'precision_dtype': u'float32', u'num_classes': u'2'}\u001b[0m\n",
      "\u001b[34m[07/01/2020 12:59:42 INFO 140326804956992] Final configuration: {u'optimizer': u'sgd', u'learning_rate': 0.1, u'epochs': u'30', u'lr_scheduler_factor': 0.1, u'num_layers': u'50', u'precision_dtype': u'float32', u'mini_batch_size': u'128', u'num_classes': u'2', u'beta_1': 0.9, u'beta_2': 0.999, u'use_pretrained_model': u'0', u'eps': 1e-08, u'weight_decay': 0.0001, u'momentum': 0, u'image_shape': u'3,224,224', u'gamma': 0.9, u'num_training_samples': u'22500'}\u001b[0m\n",
      "\u001b[34m[07/01/2020 12:59:42 INFO 140326804956992] Searching for .rec files in /opt/ml/input/data/train.\u001b[0m\n",
      "\u001b[34m[07/01/2020 12:59:42 INFO 140326804956992] Searching for .rec files in /opt/ml/input/data/validation.\u001b[0m\n",
      "\u001b[34m[07/01/2020 12:59:42 INFO 140326804956992] use_pretrained_model: 0\u001b[0m\n",
      "\u001b[34m[07/01/2020 12:59:42 INFO 140326804956992] multi_label: 0\u001b[0m\n",
      "\u001b[34m[07/01/2020 12:59:42 INFO 140326804956992] Performing random weight initialization\u001b[0m\n",
      "\u001b[34m[07/01/2020 12:59:42 INFO 140326804956992] ---- Parameters ----\u001b[0m\n",
      "\u001b[34m[07/01/2020 12:59:42 INFO 140326804956992] num_layers: 50\u001b[0m\n",
      "\u001b[34m[07/01/2020 12:59:42 INFO 140326804956992] data type: <type 'numpy.float32'>\u001b[0m\n",
      "\u001b[34m[07/01/2020 12:59:42 INFO 140326804956992] epochs: 30\u001b[0m\n",
      "\u001b[34m[07/01/2020 12:59:42 INFO 140326804956992] optimizer: sgd\u001b[0m\n",
      "\u001b[34m[07/01/2020 12:59:42 INFO 140326804956992] momentum: 0.9\u001b[0m\n",
      "\u001b[34m[07/01/2020 12:59:42 INFO 140326804956992] weight_decay: 0.0001\u001b[0m\n",
      "\u001b[34m[07/01/2020 12:59:42 INFO 140326804956992] learning_rate: 0.1\u001b[0m\n",
      "\u001b[34m[07/01/2020 12:59:42 INFO 140326804956992] num_training_samples: 22500\u001b[0m\n",
      "\u001b[34m[07/01/2020 12:59:42 INFO 140326804956992] mini_batch_size: 128\u001b[0m\n",
      "\u001b[34m[07/01/2020 12:59:42 INFO 140326804956992] image_shape: 3,224,224\u001b[0m\n",
      "\u001b[34m[07/01/2020 12:59:42 INFO 140326804956992] num_classes: 2\u001b[0m\n",
      "\u001b[34m[07/01/2020 12:59:42 INFO 140326804956992] augmentation_type: None\u001b[0m\n",
      "\u001b[34m[07/01/2020 12:59:42 INFO 140326804956992] kv_store: device\u001b[0m\n",
      "\u001b[34m[07/01/2020 12:59:42 INFO 140326804956992] checkpoint_frequency not set, will store the best model\u001b[0m\n",
      "\u001b[34m[07/01/2020 12:59:42 INFO 140326804956992] --------------------\u001b[0m\n",
      "\u001b[34m[07/01/2020 12:59:43 INFO 140326804956992] Setting number of threads: 7\u001b[0m\n",
      "\u001b[34m[12:59:51] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.3.x_ecl_Cuda_10.1.x.2633.0/AL2012/generic-flavor/src/src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:97: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\u001b[0m\n",
      "\n",
      "2020-07-01 12:59:39 Training - Training image download completed. Training in progress.\u001b[34m[07/01/2020 13:00:01 INFO 140326804956992] Epoch[0] Batch [20]#011Speed: 237.809 samples/sec#011accuracy=0.497768\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:00:08 INFO 140326804956992] Epoch[0] Batch [40]#011Speed: 286.324 samples/sec#011accuracy=0.508194\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:00:15 INFO 140326804956992] Epoch[0] Batch [60]#011Speed: 307.284 samples/sec#011accuracy=0.512295\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:00:23 INFO 140326804956992] Epoch[0] Batch [80]#011Speed: 318.909 samples/sec#011accuracy=0.520640\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:00:30 INFO 140326804956992] Epoch[0] Batch [100]#011Speed: 326.282 samples/sec#011accuracy=0.522664\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:00:37 INFO 140326804956992] Epoch[0] Batch [120]#011Speed: 331.368 samples/sec#011accuracy=0.523567\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:00:44 INFO 140326804956992] Epoch[0] Batch [140]#011Speed: 335.085 samples/sec#011accuracy=0.521941\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:00:51 INFO 140326804956992] Epoch[0] Batch [160]#011Speed: 337.940 samples/sec#011accuracy=0.523001\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:00:56 INFO 140326804956992] Epoch[0] Train-accuracy=0.524509\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:00:56 INFO 140326804956992] Epoch[0] Time cost=65.568\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:00:59 INFO 140326804956992] Epoch[0] Validation-accuracy=0.533203\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:00:59 INFO 140326804956992] Storing the best model with validation accuracy: 0.533203\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:00:59 INFO 140326804956992] Saved checkpoint to \"/opt/ml/model/image-classification-0001.params\"\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:01:06 INFO 140326804956992] Epoch[1] Batch [20]#011Speed: 351.573 samples/sec#011accuracy=0.574405\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:01:13 INFO 140326804956992] Epoch[1] Batch [40]#011Speed: 355.274 samples/sec#011accuracy=0.597942\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:01:20 INFO 140326804956992] Epoch[1] Batch [60]#011Speed: 356.455 samples/sec#011accuracy=0.599641\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:01:28 INFO 140326804956992] Epoch[1] Batch [80]#011Speed: 356.904 samples/sec#011accuracy=0.610725\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:01:35 INFO 140326804956992] Epoch[1] Batch [100]#011Speed: 357.146 samples/sec#011accuracy=0.618038\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:01:42 INFO 140326804956992] Epoch[1] Batch [120]#011Speed: 357.289 samples/sec#011accuracy=0.621191\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:01:49 INFO 140326804956992] Epoch[1] Batch [140]#011Speed: 357.403 samples/sec#011accuracy=0.625055\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:01:56 INFO 140326804956992] Epoch[1] Batch [160]#011Speed: 357.520 samples/sec#011accuracy=0.629755\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:02:01 INFO 140326804956992] Epoch[1] Train-accuracy=0.632589\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:02:01 INFO 140326804956992] Epoch[1] Time cost=62.257\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:02:04 INFO 140326804956992] Epoch[1] Validation-accuracy=0.632422\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:02:04 INFO 140326804956992] Storing the best model with validation accuracy: 0.632422\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:02:04 INFO 140326804956992] Saved checkpoint to \"/opt/ml/model/image-classification-0002.params\"\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:02:11 INFO 140326804956992] Epoch[2] Batch [20]#011Speed: 350.608 samples/sec#011accuracy=0.653646\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:02:18 INFO 140326804956992] Epoch[2] Batch [40]#011Speed: 353.984 samples/sec#011accuracy=0.658918\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:02:26 INFO 140326804956992] Epoch[2] Batch [60]#011Speed: 355.220 samples/sec#011accuracy=0.655738\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:02:33 INFO 140326804956992] Epoch[2] Batch [80]#011Speed: 355.693 samples/sec#011accuracy=0.660204\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:02:40 INFO 140326804956992] Epoch[2] Batch [100]#011Speed: 355.924 samples/sec#011accuracy=0.662670\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:02:47 INFO 140326804956992] Epoch[2] Batch [120]#011Speed: 356.017 samples/sec#011accuracy=0.665160\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:02:54 INFO 140326804956992] Epoch[2] Batch [140]#011Speed: 356.104 samples/sec#011accuracy=0.665836\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:03:01 INFO 140326804956992] Epoch[2] Batch [160]#011Speed: 356.202 samples/sec#011accuracy=0.667314\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:03:06 INFO 140326804956992] Epoch[2] Train-accuracy=0.668036\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:03:06 INFO 140326804956992] Epoch[2] Time cost=62.489\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:03:09 INFO 140326804956992] Epoch[2] Validation-accuracy=0.671464\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:03:09 INFO 140326804956992] Storing the best model with validation accuracy: 0.671464\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:03:09 INFO 140326804956992] Saved checkpoint to \"/opt/ml/model/image-classification-0003.params\"\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:03:17 INFO 140326804956992] Epoch[3] Batch [20]#011Speed: 342.935 samples/sec#011accuracy=0.681920\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[07/01/2020 13:03:24 INFO 140326804956992] Epoch[3] Batch [40]#011Speed: 349.796 samples/sec#011accuracy=0.686547\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:03:31 INFO 140326804956992] Epoch[3] Batch [60]#011Speed: 352.066 samples/sec#011accuracy=0.687116\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:03:38 INFO 140326804956992] Epoch[3] Batch [80]#011Speed: 353.082 samples/sec#011accuracy=0.691551\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:03:45 INFO 140326804956992] Epoch[3] Batch [100]#011Speed: 353.754 samples/sec#011accuracy=0.696241\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:03:53 INFO 140326804956992] Epoch[3] Batch [120]#011Speed: 354.228 samples/sec#011accuracy=0.697508\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:04:00 INFO 140326804956992] Epoch[3] Batch [140]#011Speed: 354.567 samples/sec#011accuracy=0.698582\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:04:07 INFO 140326804956992] Epoch[3] Batch [160]#011Speed: 354.845 samples/sec#011accuracy=0.699680\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:04:12 INFO 140326804956992] Epoch[3] Train-accuracy=0.700759\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:04:12 INFO 140326804956992] Epoch[3] Time cost=62.705\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:04:14 INFO 140326804956992] Epoch[3] Validation-accuracy=0.687500\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:04:15 INFO 140326804956992] Storing the best model with validation accuracy: 0.687500\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:04:15 INFO 140326804956992] Saved checkpoint to \"/opt/ml/model/image-classification-0004.params\"\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:04:22 INFO 140326804956992] Epoch[4] Batch [20]#011Speed: 343.257 samples/sec#011accuracy=0.729167\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:04:29 INFO 140326804956992] Epoch[4] Batch [40]#011Speed: 349.956 samples/sec#011accuracy=0.721037\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:04:37 INFO 140326804956992] Epoch[4] Batch [60]#011Speed: 352.179 samples/sec#011accuracy=0.721055\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:04:44 INFO 140326804956992] Epoch[4] Batch [80]#011Speed: 353.226 samples/sec#011accuracy=0.719715\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:04:51 INFO 140326804956992] Epoch[4] Batch [100]#011Speed: 353.708 samples/sec#011accuracy=0.720220\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:04:58 INFO 140326804956992] Epoch[4] Batch [120]#011Speed: 354.185 samples/sec#011accuracy=0.724496\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:05:05 INFO 140326804956992] Epoch[4] Batch [140]#011Speed: 354.527 samples/sec#011accuracy=0.725565\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:05:13 INFO 140326804956992] Epoch[4] Batch [160]#011Speed: 354.810 samples/sec#011accuracy=0.728164\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:05:18 INFO 140326804956992] Epoch[4] Train-accuracy=0.728348\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:05:18 INFO 140326804956992] Epoch[4] Time cost=62.715\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:05:20 INFO 140326804956992] Epoch[4] Validation-accuracy=0.703947\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:05:20 INFO 140326804956992] Storing the best model with validation accuracy: 0.703947\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:05:20 INFO 140326804956992] Saved checkpoint to \"/opt/ml/model/image-classification-0005.params\"\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:05:28 INFO 140326804956992] Epoch[5] Batch [20]#011Speed: 349.351 samples/sec#011accuracy=0.750000\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:05:35 INFO 140326804956992] Epoch[5] Batch [40]#011Speed: 352.989 samples/sec#011accuracy=0.737424\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:05:42 INFO 140326804956992] Epoch[5] Batch [60]#011Speed: 354.304 samples/sec#011accuracy=0.740779\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:05:49 INFO 140326804956992] Epoch[5] Batch [80]#011Speed: 354.893 samples/sec#011accuracy=0.742284\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:05:56 INFO 140326804956992] Epoch[5] Batch [100]#011Speed: 355.250 samples/sec#011accuracy=0.743580\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:06:04 INFO 140326804956992] Epoch[5] Batch [120]#011Speed: 355.416 samples/sec#011accuracy=0.747998\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:06:11 INFO 140326804956992] Epoch[5] Batch [140]#011Speed: 355.617 samples/sec#011accuracy=0.748726\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:06:18 INFO 140326804956992] Epoch[5] Batch [160]#011Speed: 355.761 samples/sec#011accuracy=0.750146\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:06:23 INFO 140326804956992] Epoch[5] Train-accuracy=0.751027\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:06:23 INFO 140326804956992] Epoch[5] Time cost=62.567\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:06:25 INFO 140326804956992] Epoch[5] Validation-accuracy=0.719141\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:06:25 INFO 140326804956992] Storing the best model with validation accuracy: 0.719141\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:06:26 INFO 140326804956992] Saved checkpoint to \"/opt/ml/model/image-classification-0006.params\"\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:06:33 INFO 140326804956992] Epoch[6] Batch [20]#011Speed: 348.810 samples/sec#011accuracy=0.772693\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:06:40 INFO 140326804956992] Epoch[6] Batch [40]#011Speed: 352.594 samples/sec#011accuracy=0.776867\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:06:47 INFO 140326804956992] Epoch[6] Batch [60]#011Speed: 353.881 samples/sec#011accuracy=0.775487\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:06:55 INFO 140326804956992] Epoch[6] Batch [80]#011Speed: 354.600 samples/sec#011accuracy=0.778742\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:07:02 INFO 140326804956992] Epoch[6] Batch [100]#011Speed: 355.015 samples/sec#011accuracy=0.777924\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:07:09 INFO 140326804956992] Epoch[6] Batch [120]#011Speed: 355.277 samples/sec#011accuracy=0.778926\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:07:16 INFO 140326804956992] Epoch[6] Batch [140]#011Speed: 355.505 samples/sec#011accuracy=0.779255\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:07:23 INFO 140326804956992] Epoch[6] Batch [160]#011Speed: 355.642 samples/sec#011accuracy=0.780134\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:07:28 INFO 140326804956992] Epoch[6] Train-accuracy=0.780759\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:07:28 INFO 140326804956992] Epoch[6] Time cost=62.584\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:07:31 INFO 140326804956992] Epoch[6] Validation-accuracy=0.783306\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:07:31 INFO 140326804956992] Storing the best model with validation accuracy: 0.783306\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:07:31 INFO 140326804956992] Saved checkpoint to \"/opt/ml/model/image-classification-0007.params\"\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:07:39 INFO 140326804956992] Epoch[7] Batch [20]#011Speed: 342.931 samples/sec#011accuracy=0.803943\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:07:46 INFO 140326804956992] Epoch[7] Batch [40]#011Speed: 349.607 samples/sec#011accuracy=0.800495\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:07:53 INFO 140326804956992] Epoch[7] Batch [60]#011Speed: 351.939 samples/sec#011accuracy=0.802382\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:08:00 INFO 140326804956992] Epoch[7] Batch [80]#011Speed: 353.061 samples/sec#011accuracy=0.801794\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:08:07 INFO 140326804956992] Epoch[7] Batch [100]#011Speed: 353.764 samples/sec#011accuracy=0.803063\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:08:14 INFO 140326804956992] Epoch[7] Batch [120]#011Speed: 354.194 samples/sec#011accuracy=0.804236\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:08:22 INFO 140326804956992] Epoch[7] Batch [140]#011Speed: 354.522 samples/sec#011accuracy=0.805075\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:08:29 INFO 140326804956992] Epoch[7] Batch [160]#011Speed: 354.769 samples/sec#011accuracy=0.805415\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:08:34 INFO 140326804956992] Epoch[7] Train-accuracy=0.807277\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:08:34 INFO 140326804956992] Epoch[7] Time cost=62.728\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:08:36 INFO 140326804956992] Epoch[7] Validation-accuracy=0.792188\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:08:36 INFO 140326804956992] Storing the best model with validation accuracy: 0.792188\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:08:37 INFO 140326804956992] Saved checkpoint to \"/opt/ml/model/image-classification-0008.params\"\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:08:44 INFO 140326804956992] Epoch[8] Batch [20]#011Speed: 342.469 samples/sec#011accuracy=0.822173\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:08:51 INFO 140326804956992] Epoch[8] Batch [40]#011Speed: 349.366 samples/sec#011accuracy=0.818026\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:08:59 INFO 140326804956992] Epoch[8] Batch [60]#011Speed: 351.817 samples/sec#011accuracy=0.823770\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:09:06 INFO 140326804956992] Epoch[8] Batch [80]#011Speed: 353.033 samples/sec#011accuracy=0.825231\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:09:13 INFO 140326804956992] Epoch[8] Batch [100]#011Speed: 353.755 samples/sec#011accuracy=0.828744\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:09:20 INFO 140326804956992] Epoch[8] Batch [120]#011Speed: 354.246 samples/sec#011accuracy=0.827867\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:09:27 INFO 140326804956992] Epoch[8] Batch [140]#011Speed: 354.570 samples/sec#011accuracy=0.829510\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:09:34 INFO 140326804956992] Epoch[8] Batch [160]#011Speed: 354.841 samples/sec#011accuracy=0.830163\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[07/01/2020 13:09:39 INFO 140326804956992] Epoch[8] Train-accuracy=0.831205\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:09:39 INFO 140326804956992] Epoch[8] Time cost=62.710\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:09:42 INFO 140326804956992] Epoch[8] Validation-accuracy=0.786595\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:09:50 INFO 140326804956992] Epoch[9] Batch [20]#011Speed: 342.783 samples/sec#011accuracy=0.843750\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:09:57 INFO 140326804956992] Epoch[9] Batch [40]#011Speed: 349.514 samples/sec#011accuracy=0.849085\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:10:04 INFO 140326804956992] Epoch[9] Batch [60]#011Speed: 351.835 samples/sec#011accuracy=0.850410\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:10:11 INFO 140326804956992] Epoch[9] Batch [80]#011Speed: 352.951 samples/sec#011accuracy=0.852816\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:10:18 INFO 140326804956992] Epoch[9] Batch [100]#011Speed: 353.674 samples/sec#011accuracy=0.853187\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:10:25 INFO 140326804956992] Epoch[9] Batch [120]#011Speed: 354.193 samples/sec#011accuracy=0.851821\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:10:33 INFO 140326804956992] Epoch[9] Batch [140]#011Speed: 354.574 samples/sec#011accuracy=0.851507\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:10:40 INFO 140326804956992] Epoch[9] Batch [160]#011Speed: 354.823 samples/sec#011accuracy=0.851465\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:10:45 INFO 140326804956992] Epoch[9] Train-accuracy=0.854241\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:10:45 INFO 140326804956992] Epoch[9] Time cost=62.712\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:10:47 INFO 140326804956992] Epoch[9] Validation-accuracy=0.803125\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:10:47 INFO 140326804956992] Storing the best model with validation accuracy: 0.803125\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:10:48 INFO 140326804956992] Saved checkpoint to \"/opt/ml/model/image-classification-0010.params\"\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:10:55 INFO 140326804956992] Epoch[10] Batch [20]#011Speed: 349.664 samples/sec#011accuracy=0.864955\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:11:02 INFO 140326804956992] Epoch[10] Batch [40]#011Speed: 352.724 samples/sec#011accuracy=0.863377\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:11:09 INFO 140326804956992] Epoch[10] Batch [60]#011Speed: 353.943 samples/sec#011accuracy=0.868468\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:11:17 INFO 140326804956992] Epoch[10] Batch [80]#011Speed: 354.650 samples/sec#011accuracy=0.867477\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:11:24 INFO 140326804956992] Epoch[10] Batch [100]#011Speed: 355.014 samples/sec#011accuracy=0.867497\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:11:31 INFO 140326804956992] Epoch[10] Batch [120]#011Speed: 355.267 samples/sec#011accuracy=0.867575\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:11:38 INFO 140326804956992] Epoch[10] Batch [140]#011Speed: 355.479 samples/sec#011accuracy=0.867797\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:11:45 INFO 140326804956992] Epoch[10] Batch [160]#011Speed: 355.569 samples/sec#011accuracy=0.867090\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:11:50 INFO 140326804956992] Epoch[10] Train-accuracy=0.869687\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:11:50 INFO 140326804956992] Epoch[10] Time cost=62.597\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:11:53 INFO 140326804956992] Epoch[10] Validation-accuracy=0.813734\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:11:53 INFO 140326804956992] Storing the best model with validation accuracy: 0.813734\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:11:53 INFO 140326804956992] Saved checkpoint to \"/opt/ml/model/image-classification-0011.params\"\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:12:00 INFO 140326804956992] Epoch[11] Batch [20]#011Speed: 349.705 samples/sec#011accuracy=0.882068\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:12:08 INFO 140326804956992] Epoch[11] Batch [40]#011Speed: 353.135 samples/sec#011accuracy=0.877477\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:12:15 INFO 140326804956992] Epoch[11] Batch [60]#011Speed: 354.394 samples/sec#011accuracy=0.882428\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:12:22 INFO 140326804956992] Epoch[11] Batch [80]#011Speed: 354.941 samples/sec#011accuracy=0.883102\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:12:29 INFO 140326804956992] Epoch[11] Batch [100]#011Speed: 355.172 samples/sec#011accuracy=0.881962\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:12:36 INFO 140326804956992] Epoch[11] Batch [120]#011Speed: 355.365 samples/sec#011accuracy=0.884168\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:12:43 INFO 140326804956992] Epoch[11] Batch [140]#011Speed: 355.585 samples/sec#011accuracy=0.883533\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:12:51 INFO 140326804956992] Epoch[11] Batch [160]#011Speed: 355.723 samples/sec#011accuracy=0.885530\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:12:56 INFO 140326804956992] Epoch[11] Train-accuracy=0.888036\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:12:56 INFO 140326804956992] Epoch[11] Time cost=62.569\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:12:58 INFO 140326804956992] Epoch[11] Validation-accuracy=0.821875\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:12:58 INFO 140326804956992] Storing the best model with validation accuracy: 0.821875\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:12:59 INFO 140326804956992] Saved checkpoint to \"/opt/ml/model/image-classification-0012.params\"\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:13:06 INFO 140326804956992] Epoch[12] Batch [20]#011Speed: 343.648 samples/sec#011accuracy=0.898810\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:13:13 INFO 140326804956992] Epoch[12] Batch [40]#011Speed: 350.029 samples/sec#011accuracy=0.887576\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:13:20 INFO 140326804956992] Epoch[12] Batch [60]#011Speed: 352.274 samples/sec#011accuracy=0.894467\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:13:28 INFO 140326804956992] Epoch[12] Batch [80]#011Speed: 353.269 samples/sec#011accuracy=0.900752\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:13:35 INFO 140326804956992] Epoch[12] Batch [100]#011Speed: 353.784 samples/sec#011accuracy=0.899366\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:13:42 INFO 140326804956992] Epoch[12] Batch [120]#011Speed: 354.289 samples/sec#011accuracy=0.895984\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:13:49 INFO 140326804956992] Epoch[12] Batch [140]#011Speed: 354.646 samples/sec#011accuracy=0.895002\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:13:56 INFO 140326804956992] Epoch[12] Batch [160]#011Speed: 354.866 samples/sec#011accuracy=0.897079\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:14:01 INFO 140326804956992] Epoch[12] Train-accuracy=0.899062\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:14:01 INFO 140326804956992] Epoch[12] Time cost=62.706\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:14:04 INFO 140326804956992] Epoch[12] Validation-accuracy=0.827303\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:14:04 INFO 140326804956992] Storing the best model with validation accuracy: 0.827303\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:14:04 INFO 140326804956992] Saved checkpoint to \"/opt/ml/model/image-classification-0013.params\"\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:14:11 INFO 140326804956992] Epoch[13] Batch [20]#011Speed: 343.428 samples/sec#011accuracy=0.922247\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:14:19 INFO 140326804956992] Epoch[13] Batch [40]#011Speed: 349.897 samples/sec#011accuracy=0.902630\u001b[0m\n",
      "\u001b[34m[07/01/2020 13:14:26 INFO 140326804956992] Epoch[13] Batch [60]#011Speed: 352.218 samples/sec#011accuracy=0.902024\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ic.fit(inputs=s3_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "ic_endpoint_name = 'ic-'+time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "\n",
    "ic_predictor = ic.deploy(initial_instance_count=1,\n",
    "                         instance_type='ml.c5.4xlarge',\n",
    "                         endpoint_name=ic_endpoint_name,\n",
    "                         wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile and deploy the model with Neo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_path = '/'.join(ic.output_path.split('/')[:-1])\n",
    "output_path = 's3://{}/{}/output-neo/'.format(bucket, prefix)\n",
    "\n",
    "ic_neo_model = ic.compile_model(target_instance_family='ml_c5', \n",
    "                                   input_shape={'data':[1, 3, 224, 224]},\n",
    "                                   role=role,\n",
    "                                   framework='mxnet',\n",
    "                                   framework_version='1.5.1',\n",
    "                                   output_path=output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ic_neo_endpoint_name = 'ic-neo-'+time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "print(ic_neo_endpoint_name)\n",
    "\n",
    "ic_neo_model.image = get_image_uri(session.boto_region_name, 'image-classification-neo', repo_version='latest')\n",
    "\n",
    "ic_neo_predictor = ic_neo_model.deploy(endpoint_name=ic_neo_endpoint_name, \n",
    "                        initial_instance_count=1, \n",
    "                        instance_type='ml.c5.4xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download a test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dog\n",
    "!wget -O /tmp/test.jpg http://www.vision.caltech.edu/Image_Datasets/Caltech256/images/056.dog/056_0010.jpg\n",
    "file_name = '/tmp/test.jpg'\n",
    "from IPython.display import Image\n",
    "Image(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test image from file\n",
    "with open(file_name, 'rb') as f:\n",
    "    payload = f.read()\n",
    "    payload = bytearray(payload)\n",
    "\n",
    "def predict_images(predictor, iterations=1000):\n",
    "    total = 0\n",
    "    predictor.content_type = 'application/x-image'\n",
    "    for i in range(0, iterations):\n",
    "        tick = time.time()\n",
    "        response = predictor.predict(payload)\n",
    "        tock = time.time()\n",
    "        total += tock-tick\n",
    "    return total/iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "predict_images(ic_predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "predict_images(ic_neo_predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh -s $output_path\n",
    "echo $1\n",
    "aws s3 ls $1\n",
    "aws s3 cp $1model-ml_c5.tar.gz .\n",
    "tar xvfz model-ml_c5.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ic_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ic_neo_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_path = '/'.join(ic.output_path.split('/')[:-1])\n",
    "output_path = 's3://{}/{}/output-neo/'.format(bucket, prefix)\n",
    "\n",
    "ic_neo_model = ic.compile_model(target_instance_family='rasp3b', \n",
    "                                   input_shape={'data':[1, 3, 224, 224]},\n",
    "                                   role=role,\n",
    "                                   framework='mxnet',\n",
    "                                   framework_version='1.5.1',\n",
    "                                   output_path=output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
