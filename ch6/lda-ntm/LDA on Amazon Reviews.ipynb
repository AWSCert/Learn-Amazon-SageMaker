{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect and processing data manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "pip -q install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "# https://s3.amazonaws.com/amazon-reviews-pds/readme.html\n",
    "aws s3 cp s3://amazon-reviews-pds/tsv/amazon_reviews_us_Camera_v1_00.tsv.gz /tmp\n",
    "aws s3 cp s3://amazon-reviews-pds/tsv/amazon_reviews_us_Luggage_v1_00.tsv.gz /tmp\n",
    "aws s3 cp s3://amazon-reviews-pds/tsv/amazon_reviews_us_Software_v1_00.tsv.gz /tmp\n",
    "aws s3 cp s3://amazon-reviews-pds/tsv/amazon_reviews_us_Jewelry_v1_00.tsv.gz /tmp\n",
    "aws s3 cp s3://amazon-reviews-pds/tsv/amazon_reviews_us_Home_Improvement_v1_00.tsv.gz /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_lines = 1000\n",
    "\n",
    "cameras = pd.read_csv('/tmp/amazon_reviews_us_Camera_v1_00.tsv.gz', \n",
    "                      sep='\\t', compression='gzip',\n",
    "                      error_bad_lines=False, dtype='str', nrows=num_lines)\n",
    "\n",
    "luggage = pd.read_csv('/tmp/amazon_reviews_us_Luggage_v1_00.tsv.gz', \n",
    "                      sep='\\t', compression='gzip',\n",
    "                      error_bad_lines=False, dtype='str', nrows=num_lines)\n",
    "\n",
    "software = pd.read_csv('/tmp/amazon_reviews_us_Software_v1_00.tsv.gz', \n",
    "                       sep='\\t', compression='gzip',\n",
    "                       error_bad_lines=False, dtype='str', nrows=num_lines)\n",
    "\n",
    "jewelry = pd.read_csv('/tmp/amazon_reviews_us_Jewelry_v1_00.tsv.gz', \n",
    "                      sep='\\t', compression='gzip',\n",
    "                       error_bad_lines=False, dtype='str', nrows=num_lines)\n",
    "\n",
    "home = pd.read_csv('/tmp/amazon_reviews_us_Home_Improvement_v1_00.tsv.gz', \n",
    "                   sep='\\t', compression='gzip',\n",
    "                   error_bad_lines=False, dtype='str', nrows=num_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([cameras, luggage, software, jewelry, home])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['marketplace', 'customer_id', 'review_id', 'product_id', 'product_parent', 'product_title',\n",
    "                  'product_category', 'helpful_votes', 'total_votes', 'vine', 'verified_purchase', \n",
    "                  'review_headline', 'review_date', 'star_rating'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string \n",
    "\n",
    "def process_text(text):\n",
    "    for p in string.punctuation:\n",
    "        text = text.replace(p, '')\n",
    "    text = text.lower().split()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data['review_body'] = data['review_body'].apply(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from gensim import corpora\n",
    "dictionary = corpora.Dictionary(data['review_body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "data['tokens'] = data.apply(lambda row: dictionary.doc2bow(row['review_body']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['review_body'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import lil_matrix\n",
    "\n",
    "num_lines = data.shape[0]\n",
    "num_columns = len(dictionary)\n",
    "token_matrix = lil_matrix((num_lines, num_columns)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_row_to_matrix(line, row):\n",
    "    for token_id, token_count in row['tokens']:\n",
    "        token_matrix[line, token_id] = token_count\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "line = 0\n",
    "for _, row in data.iterrows():\n",
    "    add_row_to_matrix(line, row)\n",
    "    line+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io, boto3\n",
    "import sagemaker.amazon.common as smac\n",
    "\n",
    "buf = io.BytesIO()\n",
    "smac.write_spmatrix_to_sparse_tensor(buf, token_matrix, None)\n",
    "buf.seek(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "session = sagemaker.Session()\n",
    "\n",
    "bucket = session.default_bucket()\n",
    "prefix = 'amazon-reviews-lda'\n",
    "train_key = 'reviews.protobuf'\n",
    "\n",
    "obj = '{}/{}'.format(prefix, train_key)\n",
    "boto3.resource('s3').Bucket(bucket).Object(obj).upload_fileobj(buf)\n",
    "s3_train_path = 's3://{}/{}'.format(bucket,obj)\n",
    "print(s3_train_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_output = 's3://{}/{}/output/'.format(bucket, prefix)\n",
    "\n",
    "print(s3_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell if you want to use data processed by SageMaker Processing\n",
    "\n",
    "import pickle\n",
    "\n",
    "s3_train_path =\n",
    "\n",
    "!aws s3 cp DICTIONARY_PATH .\n",
    "\n",
    "with open('dictionary.pkl', 'rb') as data:\n",
    "    dictionary = pickle.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "region_name = boto3.Session().region_name\n",
    "container = get_image_uri(region_name, \"lda\", \"latest\")\n",
    "print(container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "lda = sagemaker.estimator.Estimator(container,\n",
    "                                   role, \n",
    "                                   train_instance_count=1, \n",
    "                                   train_instance_type='ml.c5.2xlarge',\n",
    "                                   output_path=s3_output,\n",
    "                                   sagemaker_session=session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.set_hyperparameters(num_topics=5, \n",
    "                        feature_dim=num_columns, \n",
    "                        mini_batch_size=num_lines,\n",
    "                        alpha0=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.fit(inputs={'train': s3_train_path})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_predictor = lda.deploy(initial_instance_count=1, instance_type='ml.t2.medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [\n",
    "\"I sold all of my Canon gear recently and went with this great Fujifilm camera. With the kit lens, it \\\n",
    "focuses with incredible speed and accuracy. The stabilization on the lens is great for video work as well. \\\n",
    "There are so many things that are great about this camera but I can't list them all. One of my favorite \\\n",
    "capabilities of this camera is the ability to use vintage manual focus lenses. With the focus peaking feature \\\n",
    "you are able to confidently nail your focus. This feature has really brought back the fun in photography for \\\n",
    "me and exploring the wealth of affordable lenses.\",\n",
    "    \n",
    "\"When I came across this camera here on Amazon I was only looking for a quick and reliable Vlogging camcorder.\\\n",
    "This is a quality camera and comes with everything you need to take great pictures. It is small, lightweight \\\n",
    "and priced decent for the quality and megapixels. It comes with an extra battery and memory card. It is a \\\n",
    "great entry-level vlogging camera and I do not think you will be disappointed for the price.\",\n",
    "           \n",
    "\"Absolutely love these tiny delicate necklaces. They are well made and so pretty on! Also the pearls are real! \\\n",
    "I didn’t think they would be but they are - pleasantly surprised. This is one of the two diferente sets and \\\n",
    "I love them both! Love love love them! I wonder if they have them in silver as well?? Wyd definitely buy \\\n",
    "them too! ;) you will not be disappointed!\",\n",
    "    \n",
    "\"Took this on a trip recently and it's everything I was hoping for. It's solid, elegant and easy to roll. \\\n",
    "The handle also feels sturdy. The outside is textured and is therefore resistant to apparent scratches. \\\n",
    "There is also a TSA approved lock in case you ever have to check this in the baggage hold. Dimensions are \\\n",
    "adequate and within specs for carry-on, however, you will have difficulty fitting this in the smaller \\\n",
    "regional planes.\"\n",
    "]      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_samples(samples, dictionary):\n",
    "    num_lines = len(samples)\n",
    "    num_columns = len(dictionary)\n",
    "    sample_matrix = lil_matrix((num_lines, num_columns)).astype('float32')\n",
    "    for line in range(0, num_lines):\n",
    "        s = samples[line]\n",
    "        s = process_text(s)\n",
    "        s = dictionary.doc2bow(s)\n",
    "        for token_id, token_count in s:\n",
    "            sample_matrix[line, token_id] = token_count\n",
    "        line+=1\n",
    "    buf = io.BytesIO()\n",
    "    smac.write_spmatrix_to_sparse_tensor(buf, sample_matrix, None)\n",
    "    buf.seek(0)\n",
    "    return buf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import json_deserializer\n",
    "\n",
    "lda_predictor.content_type = 'application/x-recordio-protobuf'\n",
    "lda_predictor.deserializer = json_deserializer\n",
    "\n",
    "response = lda_predictor.predict(process_samples(samples, dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "pprint.pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
