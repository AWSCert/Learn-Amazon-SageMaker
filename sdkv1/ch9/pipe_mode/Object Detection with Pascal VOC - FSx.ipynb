{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    " \n",
    "role = get_execution_role()\n",
    "session = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-eu-west-1-613904931467/pascalvoc/output\n"
     ]
    }
   ],
   "source": [
    "bucket = session.default_bucket()\n",
    "\n",
    "prefix = 'pascalvoc'\n",
    "\n",
    "s3_output_location = 's3://{}/{}/output'.format(bucket, prefix)\n",
    "\n",
    "print(s3_output_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update these settings with your own subnets and security group\n",
    "\n",
    "file_system_id = 'fs-07914cf5a60649dc8'\n",
    "mount_point_name = ''\n",
    "subnets = ['subnet-63715206', 'subnet-cbf5bdbc', 'subnet-59395b00']\n",
    "security_group_ids = ['sg-09238e6d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.inputs import FileSystemInput\n",
    "\n",
    "fsx_train_data = FileSystemInput(file_system_id=file_system_id,\n",
    "                             file_system_type='FSxLustre',\n",
    "                             directory_path=mount_point_name+'/pascalvoc/input/train')\n",
    "\n",
    "fsx_validation_data = FileSystemInput(file_system_id=file_system_id,\n",
    "                             file_system_type='FSxLustre',\n",
    "                             directory_path=mount_point_name+'/pascalvoc/input/validation')\n",
    "\n",
    "data_channels = {'train': fsx_train_data, 'validation': fsx_validation_data }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "region = session.boto_region_name\n",
    "container = get_image_uri(region, 'object-detection', repo_version='latest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = get_execution_role()\n",
    "\n",
    "od = sagemaker.estimator.Estimator(container,\n",
    "                                         role, \n",
    "                                         train_instance_count=1, \n",
    "                                         train_instance_type='ml.p3.2xlarge',\n",
    "                                         output_path=s3_output_location,\n",
    "                                         subnets=subnets,\n",
    "                                         security_group_ids=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "od.set_hyperparameters(base_network='resnet-50',\n",
    "                       use_pretrained_model=1,\n",
    "                       num_classes=20,\n",
    "                       epochs=30,\n",
    "                       num_training_samples=16551,\n",
    "                       mini_batch_size=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-28 08:05:46 Starting - Starting the training job...\n",
      "2020-05-28 08:05:50 Starting - Launching requested ML instances......\n",
      "2020-05-28 08:06:54 Starting - Preparing the instances for training......\n",
      "2020-05-28 08:08:06 Downloading - Downloading input data\n",
      "2020-05-28 08:08:06 Training - Downloading the training image...\n",
      "2020-05-28 08:08:40 Training - Training image download completed. Training in progress..\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:08:43 INFO 139682424452928] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/default-input.json: {u'label_width': u'350', u'early_stopping_min_epochs': u'10', u'epochs': u'30', u'overlap_threshold': u'0.5', u'lr_scheduler_factor': u'0.1', u'_num_kv_servers': u'auto', u'weight_decay': u'0.0005', u'mini_batch_size': u'32', u'use_pretrained_model': u'0', u'freeze_layer_pattern': u'', u'lr_scheduler_step': u'', u'early_stopping': u'False', u'early_stopping_patience': u'5', u'momentum': u'0.9', u'num_training_samples': u'', u'optimizer': u'sgd', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': u'0.0', u'learning_rate': u'0.001', u'kv_store': u'device', u'nms_threshold': u'0.45', u'num_classes': u'', u'base_network': u'vgg-16', u'nms_topk': u'400', u'_kvstore': u'device', u'image_shape': u'300'}\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:08:43 INFO 139682424452928] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {u'base_network': u'resnet-50', u'use_pretrained_model': u'1', u'epochs': u'30', u'num_training_samples': u'16551', u'mini_batch_size': u'90', u'num_classes': u'20'}\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:08:43 INFO 139682424452928] Final configuration: {u'label_width': u'350', u'early_stopping_min_epochs': u'10', u'epochs': u'30', u'overlap_threshold': u'0.5', u'lr_scheduler_factor': u'0.1', u'_num_kv_servers': u'auto', u'weight_decay': u'0.0005', u'mini_batch_size': u'90', u'use_pretrained_model': u'1', u'freeze_layer_pattern': u'', u'lr_scheduler_step': u'', u'early_stopping': u'False', u'early_stopping_patience': u'5', u'momentum': u'0.9', u'num_training_samples': u'16551', u'optimizer': u'sgd', u'_tuning_objective_metric': u'', u'early_stopping_tolerance': u'0.0', u'learning_rate': u'0.001', u'kv_store': u'device', u'nms_threshold': u'0.45', u'num_classes': u'20', u'base_network': u'resnet-50', u'nms_topk': u'400', u'_kvstore': u'device', u'image_shape': u'300'}\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:08:43 INFO 139682424452928] Using default worker.\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:08:43 INFO 139682424452928] Loaded iterator creator application/x-image for content type ('application/x-image', '1.0')\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:08:43 INFO 139682424452928] Loaded iterator creator application/x-recordio for content type ('application/x-recordio', '1.0')\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:08:43 INFO 139682424452928] Loaded iterator creator image/png for content type ('image/png', '1.0')\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:08:43 INFO 139682424452928] Loaded iterator creator image/jpeg for content type ('image/jpeg', '1.0')\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:08:43 INFO 139682424452928] Checkpoint loading and saving are disabled.\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:08:43 INFO 139682424452928] nvidia-smi took: 0.0503599643707 secs to identify 1 gpus\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:08:43 INFO 139682424452928] Number of GPUs being used: 1\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:08:43 WARNING 139682424452928] Training images are resized to image shape (3, 300, 300)\u001b[0m\n",
      "\u001b[34m[08:08:43] /opt/brazil-pkg-cache/packages/MXNetECL/MXNetECL-v1.4.1.1457.0/AL2012/generic-flavor/src/src/io/iter_image_det_recordio.cc:283: ImageDetRecordIOParser: /opt/ml/input/data/train/train.rec, use 7 threads for decoding..\u001b[0m\n",
      "\u001b[34m[08:08:46] /opt/brazil-pkg-cache/packages/MXNetECL/MXNetECL-v1.4.1.1457.0/AL2012/generic-flavor/src/src/io/iter_image_det_recordio.cc:340: ImageDetRecordIOParser: /opt/ml/input/data/train/train.rec, label padding width: 350\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:08:49 WARNING 139682424452928] Validation images are resized to image shape (3, 300, 300)\u001b[0m\n",
      "\u001b[34m[08:08:49] /opt/brazil-pkg-cache/packages/MXNetECL/MXNetECL-v1.4.1.1457.0/AL2012/generic-flavor/src/src/io/iter_image_det_recordio.cc:283: ImageDetRecordIOParser: /opt/ml/input/data/validation/val.rec, use 7 threads for decoding..\u001b[0m\n",
      "\u001b[34m[08:08:50] /opt/brazil-pkg-cache/packages/MXNetECL/MXNetECL-v1.4.1.1457.0/AL2012/generic-flavor/src/src/io/iter_image_det_recordio.cc:340: ImageDetRecordIOParser: /opt/ml/input/data/validation/val.rec, label padding width: 350\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:08:55 INFO 139682424452928] Number of GPUs being used: 1\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:08:55 INFO 139682424452928] Using [gpu(0)] as training context.\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:08:55 INFO 139682424452928] Number of GPUs being used: 1\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:08:55 INFO 139682424452928] Create Store: device\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:08:55 INFO 139682424452928] Using (gpu(0)) as training context.\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:08:55 INFO 139682424452928] Start training from pretrained model 1.\u001b[0m\n",
      "\u001b[34m[08:08:55] /opt/brazil-pkg-cache/packages/MXNetECL/MXNetECL-v1.4.1.1457.0/AL2012/generic-flavor/src/src/nnvm/legacy_json_util.cc:209: Loading symbol saved by previous version v0.8.0. Attempting to upgrade...\u001b[0m\n",
      "\u001b[34m[08:08:55] /opt/brazil-pkg-cache/packages/MXNetECL/MXNetECL-v1.4.1.1457.0/AL2012/generic-flavor/src/src/nnvm/legacy_json_util.cc:217: Symbol successfully upgraded!\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:08:55 INFO 139682424452928] Loaded pretrained model parameters.\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:09:16 INFO 139682424452928] Creating a new state instance.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1590653356.256868, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\"}, \"StartTime\": 1590653356.256784}\n",
      "\u001b[0m\n",
      "\u001b[34m[08:09:16] /opt/brazil-pkg-cache/packages/MXNetECL/MXNetECL-v1.4.1.1457.0/AL2012/generic-flavor/src/src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:97: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:10:31 INFO 139682424452928] Epoch:    0, batches:    100, num_examples:   9000, 119.7 samples/sec, epoch time so far:  0:01:15.178470\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:11:27 WARNING 139682424452928] Expected number of batches: 183, did not match the number of batches processed: 184. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:11:27 INFO 139682424452928] #quality_metric: host=algo-1, epoch=0, batch=184 train cross_entropy <loss>=(2.901001286288469)\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:11:27 INFO 139682424452928] #quality_metric: host=algo-1, epoch=0, batch=184 train smooth_l1 <loss>=(0.7804222060170193)\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:11:27 INFO 139682424452928] Round of batches complete\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:11:27 INFO 139682424452928] Updated the metrics\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:12:16 INFO 139682424452928] #quality_metric: host=algo-1, epoch=0, validation mAP <score>=(3.8474613108523096e-05)\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:12:16 INFO 139682424452928] Updating the best model with validation-mAP=3.8474613108523096e-05\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:12:16 INFO 139682424452928] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:12:16 INFO 139682424452928] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1590653536.994024, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 0}, \"StartTime\": 1590653356.2644}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/28/2020 08:13:27 INFO 139682424452928] Epoch:    1, batches:    100, num_examples:   9000, 127.0 samples/sec, epoch time so far:  0:01:10.864227\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:14:24 WARNING 139682424452928] Expected number of batches: 183, did not match the number of batches processed: 184. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:14:24 INFO 139682424452928] #quality_metric: host=algo-1, epoch=1, batch=184 train cross_entropy <loss>=(1.6586140477514673)\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:14:24 INFO 139682424452928] #quality_metric: host=algo-1, epoch=1, batch=184 train smooth_l1 <loss>=(0.7290871329570964)\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:14:24 INFO 139682424452928] Round of batches complete\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:14:24 INFO 139682424452928] Updated the metrics\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:15:07 INFO 139682424452928] #quality_metric: host=algo-1, epoch=1, validation mAP <score>=(0.0016984744121054003)\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:15:07 INFO 139682424452928] Updating the best model with validation-mAP=0.0016984744121054003\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:15:07 INFO 139682424452928] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:15:07 INFO 139682424452928] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 2, \"sum\": 2.0, \"min\": 2}}, \"EndTime\": 1590653707.506367, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 1}, \"StartTime\": 1590653536.99419}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:16:20 INFO 139682424452928] Epoch:    2, batches:    100, num_examples:   9000, 123.0 samples/sec, epoch time so far:  0:01:13.167054\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:17:16 WARNING 139682424452928] Expected number of batches: 183, did not match the number of batches processed: 184. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:17:16 INFO 139682424452928] #quality_metric: host=algo-1, epoch=2, batch=184 train cross_entropy <loss>=(1.2587561860277632)\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:17:16 INFO 139682424452928] #quality_metric: host=algo-1, epoch=2, batch=184 train smooth_l1 <loss>=(0.6771355189258926)\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:17:16 INFO 139682424452928] Round of batches complete\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:17:16 INFO 139682424452928] Updated the metrics\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:17:56 INFO 139682424452928] #quality_metric: host=algo-1, epoch=2, validation mAP <score>=(0.0032366596674498088)\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:17:56 INFO 139682424452928] Updating the best model with validation-mAP=0.0032366596674498088\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:17:57 INFO 139682424452928] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:17:57 INFO 139682424452928] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 3, \"sum\": 3.0, \"min\": 3}}, \"EndTime\": 1590653877.130603, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 2}, \"StartTime\": 1590653707.507275}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:19:10 INFO 139682424452928] Epoch:    3, batches:    100, num_examples:   9000, 123.3 samples/sec, epoch time so far:  0:01:12.963268\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:20:05 WARNING 139682424452928] Expected number of batches: 183, did not match the number of batches processed: 184. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:20:05 INFO 139682424452928] #quality_metric: host=algo-1, epoch=3, batch=184 train cross_entropy <loss>=(1.2235740580552803)\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:20:05 INFO 139682424452928] #quality_metric: host=algo-1, epoch=3, batch=184 train smooth_l1 <loss>=(0.6488057873365052)\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:20:05 INFO 139682424452928] Round of batches complete\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:20:05 INFO 139682424452928] Updated the metrics\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:20:45 INFO 139682424452928] #quality_metric: host=algo-1, epoch=3, validation mAP <score>=(0.0056993476992195004)\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:20:45 INFO 139682424452928] Updating the best model with validation-mAP=0.0056993476992195004\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:20:45 INFO 139682424452928] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:20:45 INFO 139682424452928] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 4, \"sum\": 4.0, \"min\": 4}}, \"EndTime\": 1590654045.5773, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 3}, \"StartTime\": 1590653877.131336}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:21:58 INFO 139682424452928] Epoch:    4, batches:    100, num_examples:   9000, 123.4 samples/sec, epoch time so far:  0:01:12.947459\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:22:54 WARNING 139682424452928] Expected number of batches: 183, did not match the number of batches processed: 184. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:22:54 INFO 139682424452928] #quality_metric: host=algo-1, epoch=4, batch=184 train cross_entropy <loss>=(1.2046004876639504)\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:22:54 INFO 139682424452928] #quality_metric: host=algo-1, epoch=4, batch=184 train smooth_l1 <loss>=(0.6452488859658847)\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:22:54 INFO 139682424452928] Round of batches complete\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:22:54 INFO 139682424452928] Updated the metrics\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:23:35 INFO 139682424452928] #quality_metric: host=algo-1, epoch=4, validation mAP <score>=(0.01099568492011585)\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:23:35 INFO 139682424452928] Updating the best model with validation-mAP=0.01099568492011585\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:23:35 INFO 139682424452928] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:23:35 INFO 139682424452928] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 5, \"sum\": 5.0, \"min\": 5}}, \"EndTime\": 1590654215.834482, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 4}, \"StartTime\": 1590654045.578031}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/28/2020 08:24:48 INFO 139682424452928] Epoch:    5, batches:    100, num_examples:   9000, 123.8 samples/sec, epoch time so far:  0:01:12.671812\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:25:43 WARNING 139682424452928] Expected number of batches: 183, did not match the number of batches processed: 184. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:25:43 INFO 139682424452928] #quality_metric: host=algo-1, epoch=5, batch=184 train cross_entropy <loss>=(1.189043409977805)\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:25:43 INFO 139682424452928] #quality_metric: host=algo-1, epoch=5, batch=184 train smooth_l1 <loss>=(0.6308928188814054)\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:25:43 INFO 139682424452928] Round of batches complete\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:25:43 INFO 139682424452928] Updated the metrics\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:26:24 INFO 139682424452928] #quality_metric: host=algo-1, epoch=5, validation mAP <score>=(0.01733458015898123)\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:26:24 INFO 139682424452928] Updating the best model with validation-mAP=0.01733458015898123\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:26:24 INFO 139682424452928] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:26:24 INFO 139682424452928] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 6, \"sum\": 6.0, \"min\": 6}}, \"EndTime\": 1590654384.567149, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 5}, \"StartTime\": 1590654215.834709}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:27:35 INFO 139682424452928] Epoch:    6, batches:    100, num_examples:   9000, 126.7 samples/sec, epoch time so far:  0:01:11.037775\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:28:31 WARNING 139682424452928] Expected number of batches: 183, did not match the number of batches processed: 184. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:28:31 INFO 139682424452928] #quality_metric: host=algo-1, epoch=6, batch=184 train cross_entropy <loss>=(1.1762830832546656)\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:28:31 INFO 139682424452928] #quality_metric: host=algo-1, epoch=6, batch=184 train smooth_l1 <loss>=(0.6228698021838714)\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:28:31 INFO 139682424452928] Round of batches complete\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:28:31 INFO 139682424452928] Updated the metrics\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:29:11 INFO 139682424452928] #quality_metric: host=algo-1, epoch=6, validation mAP <score>=(0.02656446231935373)\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:29:11 INFO 139682424452928] Updating the best model with validation-mAP=0.02656446231935373\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:29:11 INFO 139682424452928] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:29:11 INFO 139682424452928] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 7, \"sum\": 7.0, \"min\": 7}}, \"EndTime\": 1590654551.987696, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 6}, \"StartTime\": 1590654384.567347}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:30:25 INFO 139682424452928] Epoch:    7, batches:    100, num_examples:   9000, 123.0 samples/sec, epoch time so far:  0:01:13.148070\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:31:19 WARNING 139682424452928] Expected number of batches: 183, did not match the number of batches processed: 184. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:31:19 INFO 139682424452928] #quality_metric: host=algo-1, epoch=7, batch=184 train cross_entropy <loss>=(1.1680768229058942)\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:31:19 INFO 139682424452928] #quality_metric: host=algo-1, epoch=7, batch=184 train smooth_l1 <loss>=(0.6041817875784368)\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:31:19 INFO 139682424452928] Round of batches complete\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:31:19 INFO 139682424452928] Updated the metrics\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:31:59 INFO 139682424452928] #quality_metric: host=algo-1, epoch=7, validation mAP <score>=(0.03769873059084475)\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:31:59 INFO 139682424452928] Updating the best model with validation-mAP=0.03769873059084475\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:31:59 INFO 139682424452928] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:31:59 INFO 139682424452928] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 8, \"sum\": 8.0, \"min\": 8}}, \"EndTime\": 1590654719.942504, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 7}, \"StartTime\": 1590654551.988032}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:33:11 INFO 139682424452928] Epoch:    8, batches:    100, num_examples:   9000, 126.5 samples/sec, epoch time so far:  0:01:11.147872\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:34:07 WARNING 139682424452928] Expected number of batches: 183, did not match the number of batches processed: 184. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:34:07 INFO 139682424452928] #quality_metric: host=algo-1, epoch=8, batch=184 train cross_entropy <loss>=(1.153853924481789)\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:34:07 INFO 139682424452928] #quality_metric: host=algo-1, epoch=8, batch=184 train smooth_l1 <loss>=(0.5881106311186148)\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:34:07 INFO 139682424452928] Round of batches complete\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:34:07 INFO 139682424452928] Updated the metrics\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:34:48 INFO 139682424452928] #quality_metric: host=algo-1, epoch=8, validation mAP <score>=(0.053658660532238764)\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:34:48 INFO 139682424452928] Updating the best model with validation-mAP=0.053658660532238764\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:34:48 INFO 139682424452928] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:34:48 INFO 139682424452928] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 9, \"sum\": 9.0, \"min\": 9}}, \"EndTime\": 1590654888.252728, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 8}, \"StartTime\": 1590654719.942732}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/28/2020 08:36:00 INFO 139682424452928] Epoch:    9, batches:    100, num_examples:   9000, 125.1 samples/sec, epoch time so far:  0:01:11.955943\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:36:55 INFO 139682424452928] #quality_metric: host=algo-1, epoch=9, batch=183 train cross_entropy <loss>=(1.1424976680839862)\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:36:55 INFO 139682424452928] #quality_metric: host=algo-1, epoch=9, batch=183 train smooth_l1 <loss>=(0.5744026766746475)\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:36:55 INFO 139682424452928] Round of batches complete\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:36:55 INFO 139682424452928] Updated the metrics\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:37:35 INFO 139682424452928] #quality_metric: host=algo-1, epoch=9, validation mAP <score>=(0.06390672875782509)\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:37:35 INFO 139682424452928] Updating the best model with validation-mAP=0.06390672875782509\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:37:35 INFO 139682424452928] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:37:35 INFO 139682424452928] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 10, \"sum\": 10.0, \"min\": 10}}, \"EndTime\": 1590655055.6037, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 9}, \"StartTime\": 1590654888.254014}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:38:49 INFO 139682424452928] Epoch:    10, batches:    100, num_examples:   9000, 121.2 samples/sec, epoch time so far:  0:01:14.255134\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:39:44 WARNING 139682424452928] Expected number of batches: 183, did not match the number of batches processed: 184. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:39:44 INFO 139682424452928] #quality_metric: host=algo-1, epoch=10, batch=184 train cross_entropy <loss>=(1.1344048944062657)\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:39:44 INFO 139682424452928] #quality_metric: host=algo-1, epoch=10, batch=184 train smooth_l1 <loss>=(0.5720866444168418)\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:39:44 INFO 139682424452928] Round of batches complete\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:39:44 INFO 139682424452928] Updated the metrics\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:40:24 INFO 139682424452928] #quality_metric: host=algo-1, epoch=10, validation mAP <score>=(0.07073298795452838)\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:40:24 INFO 139682424452928] Updating the best model with validation-mAP=0.07073298795452838\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:40:24 INFO 139682424452928] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:40:24 INFO 139682424452928] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 11, \"sum\": 11.0, \"min\": 11}}, \"EndTime\": 1590655224.866376, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 10}, \"StartTime\": 1590655055.604334}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:41:37 INFO 139682424452928] Epoch:    11, batches:    100, num_examples:   9000, 123.3 samples/sec, epoch time so far:  0:01:12.984296\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:42:33 WARNING 139682424452928] Expected number of batches: 183, did not match the number of batches processed: 184. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:42:33 INFO 139682424452928] #quality_metric: host=algo-1, epoch=11, batch=184 train cross_entropy <loss>=(1.1260389649098717)\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:42:33 INFO 139682424452928] #quality_metric: host=algo-1, epoch=11, batch=184 train smooth_l1 <loss>=(0.5585295050863651)\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:42:33 INFO 139682424452928] Round of batches complete\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:42:33 INFO 139682424452928] Updated the metrics\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:43:13 INFO 139682424452928] #quality_metric: host=algo-1, epoch=11, validation mAP <score>=(0.08086670830895379)\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:43:13 INFO 139682424452928] Updating the best model with validation-mAP=0.08086670830895379\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:43:13 INFO 139682424452928] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:43:13 INFO 139682424452928] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 12, \"sum\": 12.0, \"min\": 12}}, \"EndTime\": 1590655393.803898, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 11}, \"StartTime\": 1590655224.86666}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:44:25 INFO 139682424452928] Epoch:    12, batches:    100, num_examples:   9000, 124.7 samples/sec, epoch time so far:  0:01:12.169453\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:45:21 WARNING 139682424452928] Expected number of batches: 183, did not match the number of batches processed: 184. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:45:21 INFO 139682424452928] #quality_metric: host=algo-1, epoch=12, batch=184 train cross_entropy <loss>=(1.1188352128194752)\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:45:21 INFO 139682424452928] #quality_metric: host=algo-1, epoch=12, batch=184 train smooth_l1 <loss>=(0.5558318855107184)\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:45:21 INFO 139682424452928] Round of batches complete\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:45:21 INFO 139682424452928] Updated the metrics\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:46:02 INFO 139682424452928] #quality_metric: host=algo-1, epoch=12, validation mAP <score>=(0.09071297340895762)\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:46:02 INFO 139682424452928] Updating the best model with validation-mAP=0.09071297340895762\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:46:02 INFO 139682424452928] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:46:02 INFO 139682424452928] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 13, \"sum\": 13.0, \"min\": 13}}, \"EndTime\": 1590655562.339348, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 12}, \"StartTime\": 1590655393.804125}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/28/2020 08:47:14 INFO 139682424452928] Epoch:    13, batches:    100, num_examples:   9000, 125.0 samples/sec, epoch time so far:  0:01:11.998442\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:48:10 WARNING 139682424452928] Expected number of batches: 183, did not match the number of batches processed: 184. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:48:10 INFO 139682424452928] #quality_metric: host=algo-1, epoch=13, batch=184 train cross_entropy <loss>=(1.1087657456803937)\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:48:10 INFO 139682424452928] #quality_metric: host=algo-1, epoch=13, batch=184 train smooth_l1 <loss>=(0.5383844458690645)\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:48:10 INFO 139682424452928] Round of batches complete\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:48:10 INFO 139682424452928] Updated the metrics\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:48:51 INFO 139682424452928] #quality_metric: host=algo-1, epoch=13, validation mAP <score>=(0.09900629708288655)\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:48:51 INFO 139682424452928] Updating the best model with validation-mAP=0.09900629708288655\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:48:51 INFO 139682424452928] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:48:51 INFO 139682424452928] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 14, \"sum\": 14.0, \"min\": 14}}, \"EndTime\": 1590655731.155658, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 13}, \"StartTime\": 1590655562.339599}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:50:03 INFO 139682424452928] Epoch:    14, batches:    100, num_examples:   9000, 124.6 samples/sec, epoch time so far:  0:01:12.259198\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:50:58 WARNING 139682424452928] Expected number of batches: 183, did not match the number of batches processed: 184. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:50:58 INFO 139682424452928] #quality_metric: host=algo-1, epoch=14, batch=184 train cross_entropy <loss>=(1.100374312373824)\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:50:58 INFO 139682424452928] #quality_metric: host=algo-1, epoch=14, batch=184 train smooth_l1 <loss>=(0.5357245045516704)\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:50:58 INFO 139682424452928] Round of batches complete\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:50:58 INFO 139682424452928] Updated the metrics\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:51:39 INFO 139682424452928] #quality_metric: host=algo-1, epoch=14, validation mAP <score>=(0.10668933007427177)\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:51:39 INFO 139682424452928] Updating the best model with validation-mAP=0.10668933007427177\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:51:39 INFO 139682424452928] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:51:39 INFO 139682424452928] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 15, \"sum\": 15.0, \"min\": 15}}, \"EndTime\": 1590655899.561925, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 14}, \"StartTime\": 1590655731.155911}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:52:50 INFO 139682424452928] Epoch:    15, batches:    100, num_examples:   9000, 127.1 samples/sec, epoch time so far:  0:01:10.790650\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:53:47 WARNING 139682424452928] Expected number of batches: 183, did not match the number of batches processed: 184. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:53:47 INFO 139682424452928] #quality_metric: host=algo-1, epoch=15, batch=184 train cross_entropy <loss>=(1.0945370126398597)\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:53:47 INFO 139682424452928] #quality_metric: host=algo-1, epoch=15, batch=184 train smooth_l1 <loss>=(0.5240229600934786)\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:53:47 INFO 139682424452928] Round of batches complete\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:53:47 INFO 139682424452928] Updated the metrics\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:54:27 INFO 139682424452928] #quality_metric: host=algo-1, epoch=15, validation mAP <score>=(0.11559106262405008)\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:54:27 INFO 139682424452928] Updating the best model with validation-mAP=0.11559106262405008\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:54:27 INFO 139682424452928] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:54:27 INFO 139682424452928] #progress_metric: host=algo-1, completed 53 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 16, \"sum\": 16.0, \"min\": 16}}, \"EndTime\": 1590656067.454239, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 15}, \"StartTime\": 1590655899.562116}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:55:39 INFO 139682424452928] Epoch:    16, batches:    100, num_examples:   9000, 124.9 samples/sec, epoch time so far:  0:01:12.066740\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:56:34 WARNING 139682424452928] Expected number of batches: 183, did not match the number of batches processed: 184. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:56:34 INFO 139682424452928] #quality_metric: host=algo-1, epoch=16, batch=184 train cross_entropy <loss>=(1.0836587514927571)\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:56:34 INFO 139682424452928] #quality_metric: host=algo-1, epoch=16, batch=184 train smooth_l1 <loss>=(0.5181334893333527)\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:56:34 INFO 139682424452928] Round of batches complete\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:56:34 INFO 139682424452928] Updated the metrics\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:57:14 INFO 139682424452928] #quality_metric: host=algo-1, epoch=16, validation mAP <score>=(0.12083710394898825)\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:57:14 INFO 139682424452928] Updating the best model with validation-mAP=0.12083710394898825\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:57:14 INFO 139682424452928] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:57:15 INFO 139682424452928] #progress_metric: host=algo-1, completed 56 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 17, \"sum\": 17.0, \"min\": 17}}, \"EndTime\": 1590656235.003794, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 16}, \"StartTime\": 1590656067.454881}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/28/2020 08:58:27 INFO 139682424452928] Epoch:    17, batches:    100, num_examples:   9000, 123.7 samples/sec, epoch time so far:  0:01:12.758798\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:59:23 WARNING 139682424452928] Expected number of batches: 183, did not match the number of batches processed: 184. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:59:23 INFO 139682424452928] #quality_metric: host=algo-1, epoch=17, batch=184 train cross_entropy <loss>=(1.0779719505755907)\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:59:23 INFO 139682424452928] #quality_metric: host=algo-1, epoch=17, batch=184 train smooth_l1 <loss>=(0.5169386700871883)\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:59:23 INFO 139682424452928] Round of batches complete\u001b[0m\n",
      "\u001b[34m[05/28/2020 08:59:23 INFO 139682424452928] Updated the metrics\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:00:04 INFO 139682424452928] #quality_metric: host=algo-1, epoch=17, validation mAP <score>=(0.1346542614723774)\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:00:04 INFO 139682424452928] Updating the best model with validation-mAP=0.1346542614723774\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:00:04 INFO 139682424452928] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:00:04 INFO 139682424452928] #progress_metric: host=algo-1, completed 60 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 18, \"sum\": 18.0, \"min\": 18}}, \"EndTime\": 1590656404.958481, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 17}, \"StartTime\": 1590656235.004688}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:01:18 INFO 139682424452928] Epoch:    18, batches:    100, num_examples:   9000, 122.1 samples/sec, epoch time so far:  0:01:13.694134\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:02:14 WARNING 139682424452928] Expected number of batches: 183, did not match the number of batches processed: 184. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:02:14 INFO 139682424452928] #quality_metric: host=algo-1, epoch=18, batch=184 train cross_entropy <loss>=(1.0682091980163047)\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:02:14 INFO 139682424452928] #quality_metric: host=algo-1, epoch=18, batch=184 train smooth_l1 <loss>=(0.5049013536465438)\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:02:14 INFO 139682424452928] Round of batches complete\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:02:14 INFO 139682424452928] Updated the metrics\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:02:54 INFO 139682424452928] #quality_metric: host=algo-1, epoch=18, validation mAP <score>=(0.1415911578819005)\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:02:54 INFO 139682424452928] Updating the best model with validation-mAP=0.1415911578819005\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:02:54 INFO 139682424452928] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:02:54 INFO 139682424452928] #progress_metric: host=algo-1, completed 63 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 19, \"sum\": 19.0, \"min\": 19}}, \"EndTime\": 1590656574.798616, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 18}, \"StartTime\": 1590656404.959107}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:04:07 INFO 139682424452928] Epoch:    19, batches:    100, num_examples:   9000, 123.3 samples/sec, epoch time so far:  0:01:13.014994\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:05:02 INFO 139682424452928] #quality_metric: host=algo-1, epoch=19, batch=183 train cross_entropy <loss>=(1.062108710874885)\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:05:02 INFO 139682424452928] #quality_metric: host=algo-1, epoch=19, batch=183 train smooth_l1 <loss>=(0.5079091187538033)\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:05:02 INFO 139682424452928] Round of batches complete\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:05:02 INFO 139682424452928] Updated the metrics\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:05:42 INFO 139682424452928] #quality_metric: host=algo-1, epoch=19, validation mAP <score>=(0.15712222620118482)\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:05:42 INFO 139682424452928] Updating the best model with validation-mAP=0.15712222620118482\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:05:42 INFO 139682424452928] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:05:42 INFO 139682424452928] #progress_metric: host=algo-1, completed 66 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 20, \"sum\": 20.0, \"min\": 20}}, \"EndTime\": 1590656742.757965, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 19}, \"StartTime\": 1590656574.798856}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:06:56 INFO 139682424452928] Epoch:    20, batches:    100, num_examples:   9000, 121.6 samples/sec, epoch time so far:  0:01:14.002100\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:07:52 WARNING 139682424452928] Expected number of batches: 183, did not match the number of batches processed: 184. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:07:52 INFO 139682424452928] #quality_metric: host=algo-1, epoch=20, batch=184 train cross_entropy <loss>=(1.0511286374989304)\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:07:52 INFO 139682424452928] #quality_metric: host=algo-1, epoch=20, batch=184 train smooth_l1 <loss>=(0.4974423745695563)\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:07:52 INFO 139682424452928] Round of batches complete\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:07:52 INFO 139682424452928] Updated the metrics\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:08:33 INFO 139682424452928] #quality_metric: host=algo-1, epoch=20, validation mAP <score>=(0.16026960907210064)\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:08:33 INFO 139682424452928] Updating the best model with validation-mAP=0.16026960907210064\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:08:33 INFO 139682424452928] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:08:33 INFO 139682424452928] #progress_metric: host=algo-1, completed 70 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 21, \"sum\": 21.0, \"min\": 21}}, \"EndTime\": 1590656913.795361, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 20}, \"StartTime\": 1590656742.758174}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/28/2020 09:09:46 INFO 139682424452928] Epoch:    21, batches:    100, num_examples:   9000, 124.6 samples/sec, epoch time so far:  0:01:12.236759\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:10:41 WARNING 139682424452928] Expected number of batches: 183, did not match the number of batches processed: 184. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:10:41 INFO 139682424452928] #quality_metric: host=algo-1, epoch=21, batch=184 train cross_entropy <loss>=(1.044557544669978)\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:10:41 INFO 139682424452928] #quality_metric: host=algo-1, epoch=21, batch=184 train smooth_l1 <loss>=(0.492699546369667)\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:10:41 INFO 139682424452928] Round of batches complete\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:10:41 INFO 139682424452928] Updated the metrics\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:11:22 INFO 139682424452928] #quality_metric: host=algo-1, epoch=21, validation mAP <score>=(0.17305177009206796)\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:11:22 INFO 139682424452928] Updating the best model with validation-mAP=0.17305177009206796\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:11:22 INFO 139682424452928] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:11:22 INFO 139682424452928] #progress_metric: host=algo-1, completed 73 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 22, \"sum\": 22.0, \"min\": 22}}, \"EndTime\": 1590657082.151869, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 21}, \"StartTime\": 1590656913.795567}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:12:34 INFO 139682424452928] Epoch:    22, batches:    100, num_examples:   9000, 125.0 samples/sec, epoch time so far:  0:01:11.978979\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:13:30 WARNING 139682424452928] Expected number of batches: 183, did not match the number of batches processed: 184. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:13:30 INFO 139682424452928] #quality_metric: host=algo-1, epoch=22, batch=184 train cross_entropy <loss>=(1.0377591943927633)\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:13:30 INFO 139682424452928] #quality_metric: host=algo-1, epoch=22, batch=184 train smooth_l1 <loss>=(0.48445216839024347)\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:13:30 INFO 139682424452928] Round of batches complete\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:13:30 INFO 139682424452928] Updated the metrics\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:14:10 INFO 139682424452928] #quality_metric: host=algo-1, epoch=22, validation mAP <score>=(0.18637601991560032)\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:14:10 INFO 139682424452928] Updating the best model with validation-mAP=0.18637601991560032\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:14:10 INFO 139682424452928] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:14:10 INFO 139682424452928] #progress_metric: host=algo-1, completed 76 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 23, \"sum\": 23.0, \"min\": 23}}, \"EndTime\": 1590657250.186475, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 22}, \"StartTime\": 1590657082.152122}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:15:22 INFO 139682424452928] Epoch:    23, batches:    100, num_examples:   9000, 124.2 samples/sec, epoch time so far:  0:01:12.466740\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:16:18 WARNING 139682424452928] Expected number of batches: 183, did not match the number of batches processed: 184. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:16:18 INFO 139682424452928] #quality_metric: host=algo-1, epoch=23, batch=184 train cross_entropy <loss>=(1.0286545013351003)\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:16:18 INFO 139682424452928] #quality_metric: host=algo-1, epoch=23, batch=184 train smooth_l1 <loss>=(0.48569689324076426)\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:16:18 INFO 139682424452928] Round of batches complete\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:16:18 INFO 139682424452928] Updated the metrics\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:16:59 INFO 139682424452928] #quality_metric: host=algo-1, epoch=23, validation mAP <score>=(0.19478548864969744)\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:16:59 INFO 139682424452928] Updating the best model with validation-mAP=0.19478548864969744\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:16:59 INFO 139682424452928] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:16:59 INFO 139682424452928] #progress_metric: host=algo-1, completed 80 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 24, \"sum\": 24.0, \"min\": 24}}, \"EndTime\": 1590657419.579774, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 23}, \"StartTime\": 1590657250.186674}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:18:12 INFO 139682424452928] Epoch:    24, batches:    100, num_examples:   9000, 124.1 samples/sec, epoch time so far:  0:01:12.522259\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:19:07 WARNING 139682424452928] Expected number of batches: 183, did not match the number of batches processed: 184. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:19:07 INFO 139682424452928] #quality_metric: host=algo-1, epoch=24, batch=184 train cross_entropy <loss>=(1.020957489093269)\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:19:07 INFO 139682424452928] #quality_metric: host=algo-1, epoch=24, batch=184 train smooth_l1 <loss>=(0.47713952970158785)\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:19:07 INFO 139682424452928] Round of batches complete\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:19:07 INFO 139682424452928] Updated the metrics\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:19:47 INFO 139682424452928] #quality_metric: host=algo-1, epoch=24, validation mAP <score>=(0.2017167440722724)\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:19:47 INFO 139682424452928] Updating the best model with validation-mAP=0.2017167440722724\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:19:48 INFO 139682424452928] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:19:48 INFO 139682424452928] #progress_metric: host=algo-1, completed 83 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 25, \"sum\": 25.0, \"min\": 25}}, \"EndTime\": 1590657588.024648, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 24}, \"StartTime\": 1590657419.58058}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/28/2020 09:21:00 INFO 139682424452928] Epoch:    25, batches:    100, num_examples:   9000, 124.2 samples/sec, epoch time so far:  0:01:12.435263\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:21:56 WARNING 139682424452928] Expected number of batches: 183, did not match the number of batches processed: 184. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:21:56 INFO 139682424452928] #quality_metric: host=algo-1, epoch=25, batch=184 train cross_entropy <loss>=(1.0171928646872888)\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:21:56 INFO 139682424452928] #quality_metric: host=algo-1, epoch=25, batch=184 train smooth_l1 <loss>=(0.4754054269087408)\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:21:56 INFO 139682424452928] Round of batches complete\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:21:56 INFO 139682424452928] Updated the metrics\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:22:36 INFO 139682424452928] #quality_metric: host=algo-1, epoch=25, validation mAP <score>=(0.21077233849487684)\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:22:36 INFO 139682424452928] Updating the best model with validation-mAP=0.21077233849487684\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:22:36 INFO 139682424452928] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:22:36 INFO 139682424452928] #progress_metric: host=algo-1, completed 86 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 26, \"sum\": 26.0, \"min\": 26}}, \"EndTime\": 1590657756.999232, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 25}, \"StartTime\": 1590657588.025208}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:23:49 INFO 139682424452928] Epoch:    26, batches:    100, num_examples:   9000, 124.2 samples/sec, epoch time so far:  0:01:12.449460\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:24:44 WARNING 139682424452928] Expected number of batches: 183, did not match the number of batches processed: 184. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:24:44 INFO 139682424452928] #quality_metric: host=algo-1, epoch=26, batch=184 train cross_entropy <loss>=(1.0093374462555442)\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:24:44 INFO 139682424452928] #quality_metric: host=algo-1, epoch=26, batch=184 train smooth_l1 <loss>=(0.47094759967187105)\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:24:44 INFO 139682424452928] Round of batches complete\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:24:45 INFO 139682424452928] Updated the metrics\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:25:25 INFO 139682424452928] #quality_metric: host=algo-1, epoch=26, validation mAP <score>=(0.22686817213672614)\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:25:25 INFO 139682424452928] Updating the best model with validation-mAP=0.22686817213672614\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:25:25 INFO 139682424452928] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:25:25 INFO 139682424452928] #progress_metric: host=algo-1, completed 90 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 27, \"sum\": 27.0, \"min\": 27}}, \"EndTime\": 1590657925.762607, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 26}, \"StartTime\": 1590657757.000203}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:26:36 INFO 139682424452928] Epoch:    27, batches:    100, num_examples:   9000, 127.1 samples/sec, epoch time so far:  0:01:10.783638\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:27:33 WARNING 139682424452928] Expected number of batches: 183, did not match the number of batches processed: 184. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:27:33 INFO 139682424452928] #quality_metric: host=algo-1, epoch=27, batch=184 train cross_entropy <loss>=(1.001720190832798)\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:27:33 INFO 139682424452928] #quality_metric: host=algo-1, epoch=27, batch=184 train smooth_l1 <loss>=(0.4627506714938791)\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:27:33 INFO 139682424452928] Round of batches complete\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:27:33 INFO 139682424452928] Updated the metrics\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:28:13 INFO 139682424452928] #quality_metric: host=algo-1, epoch=27, validation mAP <score>=(0.23304347486373586)\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:28:13 INFO 139682424452928] Updating the best model with validation-mAP=0.23304347486373586\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:28:13 INFO 139682424452928] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:28:13 INFO 139682424452928] #progress_metric: host=algo-1, completed 93 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 28, \"sum\": 28.0, \"min\": 28}}, \"EndTime\": 1590658093.902235, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 27}, \"StartTime\": 1590657925.762875}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:29:26 INFO 139682424452928] Epoch:    28, batches:    100, num_examples:   9000, 123.5 samples/sec, epoch time so far:  0:01:12.893731\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:30:22 WARNING 139682424452928] Expected number of batches: 183, did not match the number of batches processed: 184. This may happen when some images or annotations are invalid and cannot be parsed. Please check the dataset and ensure it follows the format in the documentation.\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:30:22 INFO 139682424452928] #quality_metric: host=algo-1, epoch=28, batch=184 train cross_entropy <loss>=(0.9956321074115918)\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:30:22 INFO 139682424452928] #quality_metric: host=algo-1, epoch=28, batch=184 train smooth_l1 <loss>=(0.4675933691477972)\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:30:22 INFO 139682424452928] Round of batches complete\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:30:22 INFO 139682424452928] Updated the metrics\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:31:03 INFO 139682424452928] #quality_metric: host=algo-1, epoch=28, validation mAP <score>=(0.24723203814105021)\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:31:03 INFO 139682424452928] Updating the best model with validation-mAP=0.24723203814105021\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:31:03 INFO 139682424452928] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:31:03 INFO 139682424452928] #progress_metric: host=algo-1, completed 96 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 29, \"sum\": 29.0, \"min\": 29}}, \"EndTime\": 1590658263.331605, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 28}, \"StartTime\": 1590658093.902484}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/28/2020 09:32:16 INFO 139682424452928] Epoch:    29, batches:    100, num_examples:   9000, 123.0 samples/sec, epoch time so far:  0:01:13.158981\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:33:11 INFO 139682424452928] #quality_metric: host=algo-1, epoch=29, batch=183 train cross_entropy <loss>=(0.9861586545292738)\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:33:11 INFO 139682424452928] #quality_metric: host=algo-1, epoch=29, batch=183 train smooth_l1 <loss>=(0.4600855151046955)\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:33:11 INFO 139682424452928] Round of batches complete\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:33:11 INFO 139682424452928] Updated the metrics\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:33:52 INFO 139682424452928] #quality_metric: host=algo-1, epoch=29, validation mAP <score>=(0.25304284450916964)\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:33:52 INFO 139682424452928] Updating the best model with validation-mAP=0.25304284450916964\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:33:53 INFO 139682424452928] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:33:53 INFO 139682424452928] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Records Seen\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Reset Count\": {\"count\": 1, \"max\": 30, \"sum\": 30.0, \"min\": 30}}, \"EndTime\": 1590658433.057013, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\", \"epoch\": 29}, \"StartTime\": 1590658263.331805}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:33:53 WARNING 139682424452928] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:33:53 INFO 139682424452928] Saved checkpoint to \"/opt/ml/model/model_algo_1-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/28/2020 09:33:53 INFO 139682424452928] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 30, \"sum\": 30.0, \"min\": 30}, \"totaltime\": {\"count\": 1, \"max\": 5111207.660913467, \"sum\": 5111207.660913467, \"min\": 5111207.660913467}, \"setuptime\": {\"count\": 1, \"max\": 10.524988174438477, \"sum\": 10.524988174438477, \"min\": 10.524988174438477}}, \"EndTime\": 1590658434.82223, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/Object Detection\"}, \"StartTime\": 1590653323.689041}\n",
      "\u001b[0m\n",
      "\n",
      "2020-05-28 09:35:13 Uploading - Uploading generated training model"
     ]
    }
   ],
   "source": [
    "od.fit(inputs=data_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "od_predictor = od.deploy(initial_instance_count = 1, instance_type = 'ml.c5.2xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O test.jpg http://www.vision.caltech.edu/Image_Datasets/Caltech256/images/159.people/159_0090.jpg\n",
    "with open(file_name, 'rb') as image:\n",
    "    f = image.read()\n",
    "    b = bytearray(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "od_predictor.content_type = 'image/jpeg'\n",
    "results = od_predictor.predict(b)\n",
    "response = json.loads(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are in a format that is similar to the .lst format with an addition of a confidence score for each detected object. The format of the output can be represented as `[class_index, confidence_score, xmin, ymin, xmax, ymax]`. Typically, we don't consider low-confidence predictions.\n",
    "\n",
    "We have provided additional script to easily visualize the detection outputs. You can visulize the high-confidence preditions with bounding box by filtering out low-confidence detections using the script below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(detections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_detection(img_file, dets, classes=[], thresh=0.6):\n",
    "        \"\"\"\n",
    "        visualize detections in one image\n",
    "        Parameters:\n",
    "        ----------\n",
    "        img : numpy.array\n",
    "            image, in bgr format\n",
    "        dets : numpy.array\n",
    "            ssd detections, numpy.array([[id, score, x1, y1, x2, y2]...])\n",
    "            each row is one object\n",
    "        classes : tuple or list of str\n",
    "            class names\n",
    "        thresh : float\n",
    "            score threshold\n",
    "        \"\"\"\n",
    "        import random\n",
    "        import matplotlib.pyplot as plt\n",
    "        import matplotlib.image as mpimg\n",
    "\n",
    "        img=mpimg.imread(img_file)\n",
    "        plt.imshow(img)\n",
    "        height = img.shape[0]\n",
    "        width = img.shape[1]\n",
    "        colors = dict()\n",
    "        for det in dets:\n",
    "            (klass, score, x0, y0, x1, y1) = det\n",
    "            if score < thresh:\n",
    "                continue\n",
    "            cls_id = int(klass)\n",
    "            if cls_id not in colors:\n",
    "                colors[cls_id] = (random.random(), random.random(), random.random())\n",
    "            xmin = int(x0 * width)\n",
    "            ymin = int(y0 * height)\n",
    "            xmax = int(x1 * width)\n",
    "            ymax = int(y1 * height)\n",
    "            rect = plt.Rectangle((xmin, ymin), xmax - xmin,\n",
    "                                 ymax - ymin, fill=False,\n",
    "                                 edgecolor=colors[cls_id],\n",
    "                                 linewidth=3.5)\n",
    "            plt.gca().add_patch(rect)\n",
    "            class_name = str(cls_id)\n",
    "            if classes and len(classes) > cls_id:\n",
    "                class_name = classes[cls_id]\n",
    "            plt.gca().text(xmin, ymin - 2,\n",
    "                            '{:s} {:.3f}'.format(class_name, score),\n",
    "                            bbox=dict(facecolor=colors[cls_id], alpha=0.5),\n",
    "                                    fontsize=12, color='white')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of this notebook, we trained the model with only a few (10) epochs. This implies that the results might not be optimal. To achieve better detection results, you can try to tune the hyperparameters and train the model for more epochs. In our tests, the mAP can reach 0.79 on the Pascal VOC dataset after training the algorithm with `learning_rate=0.0005`, `image_shape=512` and `mini_batch_size=16` for 240 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "\n",
    "object_categories = ['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', \n",
    "                     'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', \n",
    "                     'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']\n",
    "\n",
    "# Setting a threshold 0.20 will only plot detection results that have a confidence score greater than 0.20.\n",
    "threshold = 0.30\n",
    "\n",
    "# Visualize the detections.\n",
    "visualize_detection(file_name, detections['prediction'], object_categories, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "od_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
