{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m#!/usr/bin/env python\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn.linear_model\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m LinearRegression\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn.model_selection\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m train_test_split\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn.metrics\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m mean_squared_error, r2_score\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjoblib\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m, \u001b[04m\u001b[36mjson\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m'\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "    \n",
      "    config_dir = \u001b[33m'\u001b[39;49;00m\u001b[33m/opt/ml/input/config\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "    training_dir = \u001b[33m'\u001b[39;49;00m\u001b[33m/opt/ml/input/data/training\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "    model_dir = \u001b[33m'\u001b[39;49;00m\u001b[33m/opt/ml/model\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "    \n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(os.path.join(config_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mhyperparameters.json\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)) \u001b[34mas\u001b[39;49;00m f:\n",
      "        hp = json.load(f)\n",
      "        \u001b[34mprint\u001b[39;49;00m(hp)\n",
      "        normalize = hp[\u001b[33m'\u001b[39;49;00m\u001b[33mnormalize\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\n",
      "        test_size = \u001b[36mfloat\u001b[39;49;00m(hp[\u001b[33m'\u001b[39;49;00m\u001b[33mtest-size\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "        random_state = \u001b[36mint\u001b[39;49;00m(hp[\u001b[33m'\u001b[39;49;00m\u001b[33mrandom-state\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "        \n",
      "    filename = os.path.join(training_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mhousing.csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    data = pd.read_csv(filename)\n",
      "    labels = data[[\u001b[33m'\u001b[39;49;00m\u001b[33mmedv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]]\n",
      "    samples = data.drop([\u001b[33m'\u001b[39;49;00m\u001b[33mmedv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], axis=\u001b[34m1\u001b[39;49;00m)\n",
      "    X_train, X_test, y_train, y_test = train_test_split(samples, labels, \n",
      "                                                        test_size=test_size, random_state=random_state)\n",
      "    regr = LinearRegression(normalize=normalize)\n",
      "    regr.fit(X_train, y_train)\n",
      "    y_pred = regr.predict(X_test)\n",
      "    \u001b[34mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mMean squared error: \u001b[39;49;00m\u001b[33m%.2f\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m % mean_squared_error(y_test, y_pred))\n",
      "    \u001b[34mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mCoefficient of determination: \u001b[39;49;00m\u001b[33m%.2f\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m % r2_score(y_test, y_pred))\n",
      "    \n",
      "    joblib.dump(regr, os.path.join(model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mmodel.joblib\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "pygmentize sklearn-boston-housing-generic.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FROM python:3.7\n",
      "\n",
      "RUN pip3 install --no-cache scikit-learn numpy pandas joblib\n",
      "RUN pip3 install --no-cache flask\n",
      "\n",
      "COPY sklearn-boston-housing-generic.py /usr/bin/train\n",
      "COPY sklearn-boston-housing-serve.py /usr/bin/serve\n",
      "\n",
      "RUN chmod 755 /usr/bin/train /usr/bin/serve\n",
      "\n",
      "EXPOSE 8080\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "cat Dockerfile-generic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "An error occurred (RepositoryAlreadyExistsException) when calling the CreateRepository operation: The repository with name 'sklearn-custom' already exists in the registry with id '613904931467'\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "aws ecr create-repository --repository-name sklearn-custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "export REGION=us-east-1\n",
    "export ACCOUNT_ID=`aws sts get-caller-identity --query Account --output text`\n",
    "docker build -t sklearn-custom:estimator -f Dockerfile-generic .\n",
    "export IMAGE_ID=`docker images -q sklearn-custom:estimator`\n",
    "docker tag $IMAGE_ID $ACCOUNT_ID.dkr.ecr.$REGION.amazonaws.com/sklearn-custom:estimator\n",
    "aws ecr get-login-password | docker login --username AWS --password-stdin $ACCOUNT_ID.dkr.ecr.$REGION.amazonaws.com/sklearn-custom:estimator\n",
    "docker push $ACCOUNT_ID.dkr.ecr.$REGION.amazonaws.com/sklearn-custom:estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "session = sagemaker.Session()\n",
    "account_id = session.boto_session.client('sts').get_caller_identity()['Account']\n",
    "region = session.boto_session.region_name\n",
    "\n",
    "training = 'file://.'\n",
    "output = 'file://.'\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "sk = Estimator(\n",
    "             image_name=account_id+'.dkr.ecr.'+region+'.amazonaws.com/sklearn-custom:estimator',\n",
    "             role=role,\n",
    "             train_instance_count=1, \n",
    "             train_instance_type='local',\n",
    "             output_path=output,\n",
    "             hyperparameters={\n",
    "                  'normalize': True,\n",
    "                  'test-size': 0.1,\n",
    "                  'random-state': 123\n",
    "             }\n",
    ")\n",
    "\n",
    "sk.fit({'training':training})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "tar tvfz model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_predictor = sk.deploy(instance_type='local',\n",
    "                        initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import csv_serializer\n",
    "\n",
    "test_samples = ['0.00632,18.00,2.310,0,0.5380,6.5750,65.20,4.0900,1,296.0,15.30,4.98',\n",
    "                '0.02731,0.00,7.070,0,0.4690,6.4210,78.90,4.9671,2,242.0,17.80,9.14']\n",
    "\n",
    "sk_predictor.content_type = 'text/csv'\n",
    "sk_predictor.serializer = csv_serializer\n",
    "\n",
    "response = sk_predictor.predict(test_samples)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
