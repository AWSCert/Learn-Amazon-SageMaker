{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "mdir\n",
    "pip -q install pandas scikit-learn joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding source files for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "mkdir src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile src/printmetrics.py\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "def printmetrics(y_test, y_pred):\n",
    "    print('Mean squared error: %.2f' % mean_squared_error(y_test, y_pred))\n",
    "    print('Coefficient of determination: %.2f' % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile src/sklearn-boston-housing.py\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.externals import joblib\n",
    "import argparse, os\n",
    "import printmetrics\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    model = joblib.load(os.path.join(model_dir, 'model.joblib'))\n",
    "    return model\n",
    "\n",
    "if __name__ == '__main__':\n",
    "        \n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--normalize', type=bool, default=False)\n",
    "    parser.add_argument('--test-size', type=float, default=0.1)\n",
    "    parser.add_argument('--random-state', type=int, default=123)\n",
    "    parser.add_argument('--model-dir', type=str, default=os.environ['SM_MODEL_DIR'])\n",
    "    parser.add_argument('--training', type=str, default=os.environ['SM_CHANNEL_TRAINING'])\n",
    "    \n",
    "    args, _ = parser.parse_known_args()\n",
    "    normalize = args.normalize\n",
    "    test_size = args.test_size\n",
    "    random_state = args.random_state\n",
    "    model_dir  = args.model_dir\n",
    "    training_dir = args.training\n",
    "\n",
    "    filename = os.path.join(training_dir, 'housing.csv')\n",
    "    data = pd.read_csv(filename)\n",
    "    labels = data[['medv']]\n",
    "    samples = data.drop(['medv'], axis=1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(samples, labels, \n",
    "                                                        test_size=test_size, random_state=random_state)\n",
    "    regr = LinearRegression(normalize=normalize)\n",
    "    regr.fit(X_train, y_train)\n",
    "    y_pred = regr.predict(X_test)\n",
    "    printmetrics.printmetrics(y_test, y_pred)\n",
    "    \n",
    "    model = os.path.join(model_dir, 'model.joblib')\n",
    "    joblib.dump(regr, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.sklearn import SKLearn\n",
    "\n",
    "training = 'file://.'\n",
    "output = 'file://.'\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "sk = SKLearn(entry_point='sklearn-boston-housing.py',\n",
    "             source_dir='src',\n",
    "             role=role,\n",
    "             train_instance_count=1, \n",
    "             train_instance_type='local',\n",
    "             output_path=output,\n",
    "             hyperparameters={\n",
    "                  'normalize': True,\n",
    "                  'test-size': 0.1\n",
    "              }\n",
    ")\n",
    "\n",
    "sk.fit({'training':training})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding libraries for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "mkdir lib\n",
    "pip install -q -t lib joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile src/sklearn-boston-housing-joblib.py\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import argparse, os\n",
    "\n",
    "from printmetrics import printmetrics\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    model = joblib.load(os.path.join(model_dir, 'model.joblib'))\n",
    "    return model\n",
    "\n",
    "if __name__ == '__main__':\n",
    "        \n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--normalize', type=bool, default=False)\n",
    "    parser.add_argument('--test-size', type=float, default=0.1)\n",
    "    parser.add_argument('--random-state', type=int, default=123)\n",
    "    parser.add_argument('--model-dir', type=str, default=os.environ['SM_MODEL_DIR'])\n",
    "    parser.add_argument('--training', type=str, default=os.environ['SM_CHANNEL_TRAINING'])\n",
    "    \n",
    "    args, _ = parser.parse_known_args()\n",
    "    normalize = args.normalize\n",
    "    test_size = args.test_size\n",
    "    random_state = args.random_state\n",
    "    model_dir  = args.model_dir\n",
    "    training_dir = args.training\n",
    "\n",
    "    filename = os.path.join(training_dir, 'housing.csv')\n",
    "    data = pd.read_csv(filename, delim_whitespace=True)\n",
    "    labels = data[['mdev']]\n",
    "    samples = data.drop(['mdev'], axis=1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(samples, labels, \n",
    "                                                        test_size=test_size, random_state=random_state)\n",
    "    regr = LinearRegression(normalize=normalize)\n",
    "    regr.fit(X_train, y_train)\n",
    "    y_pred = regr.predict(X_test)\n",
    "    printmetrics(y_test, y_pred)\n",
    "    \n",
    "    model = os.path.join(model_dir, 'model.joblib')\n",
    "    joblib.dump(regr, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.sklearn import SKLearn\n",
    "\n",
    "training = 'file://.'\n",
    "output = 'file://.'\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "sk = SKLearn(entry_point='sklearn-boston-housing-joblib.py',\n",
    "             source_dir='src',\n",
    "             dependencies=['lib/joblib'],\n",
    "             role=role,\n",
    "             train_instance_count=1, \n",
    "             train_instance_type='local',\n",
    "             output_path=output,\n",
    "             hyperparameters={\n",
    "                  'normalize': True,\n",
    "                  'test-size': 0.1\n",
    "              }\n",
    ")\n",
    "\n",
    "sk.fit({'training':training})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will fail with \"No module named 'joblib'\"\n",
    "sk_predictor = sk.deploy(initial_instance_count=1, instance_type='local')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing libraries in the container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_predictor = sk.deploy(initial_instance_count=1, instance_type='local')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('housing.csv', delim_whitespace=True)\n",
    "payload = data[:10].drop(['mdev'], axis=1) \n",
    "payload = payload.to_csv(header=False, index=False)\n",
    "print(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "pip install -q -t . --upgrade joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import csv_serializer, csv_deserializer\n",
    "\n",
    "sk_predictor.content_type = 'text/csv'\n",
    "sk_predictor.accept = 'text/csv'\n",
    "sk_predictor.serializer = csv_serializer\n",
    "sk_predictor.deserializer = csv_deserializer\n",
    "\n",
    "response = sk_predictor.predict(payload)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5 - run with SageMaker managed infrastructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess   = sagemaker.Session()\n",
    "bucket = sess.default_bucket()                     \n",
    "prefix = 'sklearn-boston-housing'\n",
    "\n",
    "training = sess.upload_data(path='housing.csv', key_prefix=prefix + \"/training\")\n",
    "output   = 's3://{}/{}/output/'.format(bucket,prefix)\n",
    "print(training)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk = SKLearn(entry_point='sklearn-boston-housing.py',\n",
    "             role=role,\n",
    "             train_instance_count=1, \n",
    "             train_instance_type='ml.m5.large',\n",
    "             output_path=output,\n",
    "             hyperparameters={\n",
    "                  'normalize': True,\n",
    "                  'test-size': 0.1\n",
    "              }\n",
    ")\n",
    "\n",
    "sk.fit({'training':training})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_predictor = sk.deploy(initial_instance_count=1, instance_type='ml.t2.medium')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can reuse the cells above for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
