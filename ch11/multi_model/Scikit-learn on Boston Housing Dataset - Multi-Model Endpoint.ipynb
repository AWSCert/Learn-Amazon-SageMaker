{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh \n",
    "\n",
    "algorithm_name='sklearn-boston-housing-mme'\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "\n",
    "ecr_image=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "$(aws ecr get-login --region ${region} --no-include-email --registry-ids ${account})\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full image name.\n",
    "\n",
    "# First clear out any prior version of the cloned repo\n",
    "rm -rf sagemaker-scikit-learn-container/\n",
    "\n",
    "# Clone the sklearn container repo\n",
    "git clone --single-branch --branch mme https://github.com/aws/sagemaker-scikit-learn-container.git\n",
    "cd sagemaker-scikit-learn-container/\n",
    "\n",
    "# Build the \"base\" container image that encompasses the installation of the\n",
    "# scikit-learn framework and all of the dependencies needed.\n",
    "docker build -q -t sklearn-base:0.20-2-cpu-py3 -f docker/0.20-2/base/Dockerfile.cpu --build-arg py_version=3 .\n",
    "\n",
    "# Create the SageMaker Scikit-learn Container Python package.\n",
    "python setup.py bdist_wheel --universal\n",
    "\n",
    "# Build the \"final\" container image that encompasses the installation of the\n",
    "# code that implements the SageMaker multi-model container requirements.\n",
    "docker build -q -t ${algorithm_name} -f docker/0.20-2/final/Dockerfile.cpu .\n",
    "\n",
    "docker tag ${algorithm_name} ${ecr_image}\n",
    "\n",
    "docker push ${ecr_image}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()   \n",
    "role   = sagemaker.get_execution_role()\n",
    "\n",
    "prefix = 'sklearn-boston-housing-mme'\n",
    "\n",
    "training = sess.upload_data(path='housing.csv', key_prefix=prefix + \"/training\")\n",
    "output   = 's3://{}/{}/output/'.format(bucket,prefix)\n",
    "print(training)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn import SKLearn\n",
    "\n",
    "jobs =  {}\n",
    "for test_size in [0.2, 0.1, 0.05]:\n",
    "    sk = SKLearn(entry_point='sklearn-boston-housing.py',\n",
    "                 role=role,\n",
    "                 train_instance_count=1, \n",
    "                 train_instance_type='ml.m5.large',\n",
    "                 output_path=output,\n",
    "                 hyperparameters={\n",
    "                      'normalize': True,\n",
    "                      'test-size': test_size,\n",
    "                  }\n",
    "    )\n",
    "    sk.fit({'training':training}, wait=False)\n",
    "    jobs[sk.latest_training_job.name] = {}\n",
    "    jobs[sk.latest_training_job.name]['test-size'] = test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "sm = boto3.client('sagemaker')\n",
    "\n",
    "for j in jobs.keys():\n",
    "    job = sm.describe_training_job(TrainingJobName=j)\n",
    "    jobs[j]['artifact'] = job['ModelArtifacts']['S3ModelArtifacts']\n",
    "    jobs[j]['key'] = '/'.join(job['ModelArtifacts']['S3ModelArtifacts'].split('/')[3:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh -s \"$bucket\" \"$prefix\"\n",
    "aws s3 rm --recursive s3://$1/$2/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "\n",
    "for j in jobs.keys():\n",
    "    copy_source = { 'Bucket': bucket, 'Key': jobs[j]['key'] }\n",
    "    s3.copy_object(CopySource=copy_source, Bucket=bucket, Key=prefix+'/models/'+j+'.tar.gz')\n",
    "\n",
    "response = s3.list_objects(Bucket=bucket, Prefix=prefix+'/models/')\n",
    "for o in response['Contents']:\n",
    "    print(o['Key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script = 'sklearn-boston-housing.py'\n",
    "script_archive = 's3://{}/{}/source/source.tar.gz'.format(bucket, prefix)\n",
    "\n",
    "print(script)\n",
    "print(script_archive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh -s \"$script\" \"$script_archive\"\n",
    "tar cvfz source.tar.gz $1\n",
    "aws s3 cp source.tar.gz $2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "account = boto3.client('sts').get_caller_identity()['Account']\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "container = '{}.dkr.ecr.{}.amazonaws.com/{}:latest'.format(account, region, prefix)\n",
    "\n",
    "print(container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = sm.create_model(\n",
    "    ModelName = prefix,\n",
    "    ExecutionRoleArn = role,\n",
    "    Containers = [\n",
    "        {\n",
    "            'Image': container,\n",
    "            'ModelDataUrl': 's3://{}/{}/models/'.format(bucket, prefix),\n",
    "            'Mode': 'MultiModel',\n",
    "            'Environment': {\n",
    "                'SAGEMAKER_PROGRAM' : script,\n",
    "                'SAGEMAKER_SUBMIT_DIRECTORY' : script_archive\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epc_name = prefix+'-epc'\n",
    "\n",
    "response = sm.create_endpoint_config(\n",
    "    EndpointConfigName = epc_name,\n",
    "    ProductionVariants=[{\n",
    "        'InstanceType': 'ml.m5.large',\n",
    "        'InitialInstanceCount': 1,\n",
    "        'InitialVariantWeight': 1,\n",
    "        'ModelName': prefix,\n",
    "        'VariantName': 'variant-1'}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep_name = prefix+'-ep'\n",
    "\n",
    "response = sm.create_endpoint(\n",
    "    EndpointName=ep_name,\n",
    "    EndpointConfigName=epc_name)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.describe_endpoint(EndpointName=ep_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waiter = sm.get_waiter('endpoint_in_service')\n",
    "waiter.wait(EndpointName=ep_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "\n",
    "data = pd.read_csv('housing.csv', delim_whitespace=True)\n",
    "payload = data[:1].drop(['medv'], axis=1)\n",
    "buffer = BytesIO()\n",
    "np.save(buffer, payload.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smrt = boto3.client('runtime.sagemaker')\n",
    "\n",
    "for j in jobs.keys():\n",
    "    model_name=j+'.tar.gz'\n",
    "    print(model_name)\n",
    "    response = smrt.invoke_endpoint(\n",
    "        EndpointName=ep_name,\n",
    "        TargetModel=model_name,\n",
    "        Body=buffer.getvalue(),\n",
    "        ContentType='application/x-npy')\n",
    "\n",
    "    print(response['Body'].read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk = SKLearn(entry_point='sklearn-boston-housing.py',\n",
    "                 role=role,\n",
    "                 train_instance_count=1, \n",
    "                 train_instance_type='ml.m5.large',\n",
    "                 output_path=output,\n",
    "                 hyperparameters={\n",
    "                      'normalize': False,\n",
    "                      'test-size': 0.15,\n",
    "                  }\n",
    ")\n",
    "\n",
    "sk.fit({'training':training})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job = sm.describe_training_job(TrainingJobName=sk.latest_training_job.name)\n",
    "job_name = sk.latest_training_job.name\n",
    "artifact = job['ModelArtifacts']['S3ModelArtifacts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh -s \"$artifact\" \"$bucket\" \"$prefix\" \"$job_name\"\n",
    "aws s3 cp $1 s3://$2/$3/models/$4.tar.gz\n",
    "aws s3 ls s3://$2/$3/models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=job_name+'.tar.gz'\n",
    "print(model_name)\n",
    "\n",
    "response = smrt.invoke_endpoint(\n",
    "    EndpointName=ep_name,\n",
    "    TargetModel=model_name,\n",
    "    Body=buffer.getvalue(),\n",
    "    ContentType='application/x-npy')\n",
    "\n",
    "print(response['Body'].read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.delete_endpoint(EndpointName=ep_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.delete_endpoint_config(EndpointConfigName=epc_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.delete_model(ModelName=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
