{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Factorization Machines on MovieLens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download ml-100k dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "wget http://files.grouplens.org/datasets/movielens/ml-25m.zip\n",
    "unzip ml-25m.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users=162541\n",
    "num_movies=62423\n",
    "num_ratings=25000095\n",
    "\n",
    "max_movieid=209171\n",
    "\n",
    "num_features=num_users+max_movieid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "371712\n"
     ]
    }
   ],
   "source": [
    "print(num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, sys\n",
    "import numpy as np\n",
    "from scipy.sparse import lil_matrix\n",
    "\n",
    "def loadDataset(filename, lines, columns):\n",
    "    # Features are one-hot encoded in a sparse matrix\n",
    "    X = lil_matrix((lines, columns)).astype('float32')\n",
    "    # Labels are stored in a vector\n",
    "    Y = []\n",
    "    line=0\n",
    "    with open(filename,'r') as f:\n",
    "        samples=csv.reader(f,delimiter=',')\n",
    "        next(samples)  # Skip header\n",
    "        for userId,movieId,rating,timestamp in samples:\n",
    "            X[line,int(userId)-1] = 1\n",
    "            X[line,int(num_users)+int(movieId)-1] = 1\n",
    "            Y.append(float(rating))\n",
    "            line=line+1\n",
    "    Y=np.array(Y).astype('float32')\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X, Y = loadDataset('ml-25m/ratings.csv', num_ratings, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.05, random_state=59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to protobuf and save to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker, boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = sagemaker.Session().default_bucket()\n",
    "prefix = 'fm-movielens-25m'\n",
    "\n",
    "train_key      = 'train.protobuf'\n",
    "train_prefix   = '{}/{}'.format(prefix, 'train')\n",
    "\n",
    "test_key       = 'test.protobuf'\n",
    "test_prefix    = '{}/{}'.format(prefix, 'test')\n",
    "output_prefix  = 's3://{}/{}/output'.format(bucket, prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import io\n",
    "import sagemaker.amazon.common as smac\n",
    "\n",
    "def writeDatasetToProtobuf(X, Y, bucket, prefix, key):\n",
    "    buf = io.BytesIO()\n",
    "    smac.write_spmatrix_to_sparse_tensor(buf, X, Y)\n",
    "    buf.seek(0)\n",
    "    obj = '{}/{}'.format(prefix, key)\n",
    "    boto3.resource('s3').Bucket(bucket).Object(obj).upload_fileobj(buf)\n",
    "    return 's3://{}/{}'.format(bucket,obj)\n",
    "    \n",
    "train_data = writeDatasetToProtobuf(X_train, Y_train, bucket, train_prefix, train_key)    \n",
    "test_data  = writeDatasetToProtobuf(X_test, Y_test, bucket, test_prefix, test_key)    \n",
    "  \n",
    "print(train_data)\n",
    "print(test_data)\n",
    "print('Output: {}'.format(output_prefix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to use existing files\n",
    "\n",
    "train_data = 's3://sagemaker-eu-west-1-613904931467/fm-movielens-25m/train/train.protobuf'\n",
    "test_data  = 's3://sagemaker-eu-west-1-613904931467/fm-movielens-25m/test/test.protobuf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438346466558.dkr.ecr.eu-west-1.amazonaws.com/factorization-machines:1\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import image_uris\n",
    "\n",
    "region = boto3.Session().region_name    \n",
    "container = image_uris.retrieve('factorization-machines', region)\n",
    "print(container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-24 14:36:24 Starting - Starting the training job...\n",
      "2020-07-24 14:36:26 Starting - Launching requested ML instances......\n",
      "2020-07-24 14:37:32 Starting - Preparing the instances for training...\n",
      "2020-07-24 14:38:13 Downloading - Downloading input data...\n",
      "2020-07-24 14:38:51 Training - Training image download completed. Training in progress..\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python2.7/site-packages/pandas/util/nosetester.py:13: DeprecationWarning: Importing from numpy.testing.nosetester is deprecated, import from numpy.testing instead.\n",
      "  from numpy.testing import nosetester\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:38:53 INFO 140594729453376] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-conf.json: {u'factors_lr': u'0.0001', u'linear_init_sigma': u'0.01', u'epochs': 1, u'_wd': u'1.0', u'_num_kv_servers': u'auto', u'use_bias': u'true', u'factors_init_sigma': u'0.001', u'_log_level': u'info', u'bias_init_method': u'normal', u'linear_init_method': u'normal', u'linear_lr': u'0.001', u'factors_init_method': u'normal', u'_tuning_objective_metric': u'', u'bias_wd': u'0.01', u'use_linear': u'true', u'bias_lr': u'0.1', u'mini_batch_size': u'1000', u'_use_full_symbolic': u'true', u'batch_metrics_publish_interval': u'500', u'bias_init_sigma': u'0.01', u'_num_gpus': u'auto', u'_data_format': u'record', u'factors_wd': u'0.00001', u'linear_wd': u'0.001', u'_kvstore': u'auto', u'_learning_rate': u'1.0', u'_optimizer': u'adam'}\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:38:53 INFO 140594729453376] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'epochs': u'1', u'feature_dim': u'371712', u'predictor_type': u'regressor', u'num_factors': u'64'}\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:38:53 INFO 140594729453376] Final configuration: {u'factors_lr': u'0.0001', u'linear_init_sigma': u'0.01', u'epochs': u'1', u'feature_dim': u'371712', u'num_factors': u'64', u'_wd': u'1.0', u'_num_kv_servers': u'auto', u'use_bias': u'true', u'factors_init_sigma': u'0.001', u'_log_level': u'info', u'bias_init_method': u'normal', u'linear_init_method': u'normal', u'linear_lr': u'0.001', u'factors_init_method': u'normal', u'_tuning_objective_metric': u'', u'bias_wd': u'0.01', u'use_linear': u'true', u'bias_lr': u'0.1', u'mini_batch_size': u'1000', u'_use_full_symbolic': u'true', u'batch_metrics_publish_interval': u'500', u'predictor_type': u'regressor', u'bias_init_sigma': u'0.01', u'_num_gpus': u'auto', u'_data_format': u'record', u'factors_wd': u'0.00001', u'linear_wd': u'0.001', u'_kvstore': u'auto', u'_learning_rate': u'1.0', u'_optimizer': u'adam'}\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:38:53 WARNING 140594729453376] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:38:53 INFO 140594729453376] Using default worker.\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:38:53 INFO 140594729453376] The channel 'train' is in pipe input mode under /opt/ml/input/data/train.\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:38:53 INFO 140594729453376] The channel 'test' is in pipe input mode under /opt/ml/input/data/test.\u001b[0m\n",
      "\u001b[34m[2020-07-24 14:38:53.634] [tensorio] [warning] TensorIO is already initialized; ignoring the initialization routine.\u001b[0m\n",
      "\u001b[34m[2020-07-24 14:38:53.655] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 25, \"num_examples\": 1, \"num_bytes\": 67552}\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:38:53 INFO 140594729453376] nvidia-smi took: 0.025181055069 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:38:53 INFO 140594729453376] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:38:53 INFO 140594729453376] [Sparse network] Building a sparse network.\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:38:53 INFO 140594729453376] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 51.857948303222656, \"sum\": 51.857948303222656, \"min\": 51.857948303222656}}, \"EndTime\": 1595601533.701116, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1595601533.629594}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Total Records Seen\": {\"count\": 1, \"max\": 1000, \"sum\": 1000.0, \"min\": 1000}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1000, \"sum\": 1000.0, \"min\": 1000}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1595601533.701546, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1595601533.701493}\n",
      "\u001b[0m\n",
      "\u001b[34m[14:38:53] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.1.x.202835.0/AL2012/generic-flavor/src/src/kvstore/./kvstore_local.h:280: Warning: non-default weights detected during kvstore pull. This call has been ignored. Please make sure to use row_sparse_pull with row_ids.\u001b[0m\n",
      "\u001b[34m[14:38:53] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.1.x.202835.0/AL2012/generic-flavor/src/src/kvstore/./kvstore_local.h:280: Warning: non-default weights detected during kvstore pull. This call has been ignored. Please make sure to use row_sparse_pull with row_ids.\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:38:55 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=0 train rmse <loss>=3.67073147087\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:38:55 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=0 train mse <loss>=13.4742695313\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:38:55 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=0 train absolute_loss <loss>=3.51437792969\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:39:00 INFO 140594729453376] Iter[0] Batch [500]#011Speed: 92797.12 samples/sec\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:39:00 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=500 train rmse <loss>=1.19971203504\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:39:00 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=500 train mse <loss>=1.43930896703\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:39:00 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=500 train absolute_loss <loss>=0.927512714805\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:39:05 INFO 140594729453376] Iter[0] Batch [1000]#011Speed: 110109.21 samples/sec\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:39:05 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=1000 train rmse <loss>=1.13330436154\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:39:05 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=1000 train mse <loss>=1.28437877589\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:39:05 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=1000 train absolute_loss <loss>=0.885553945383\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:39:09 INFO 140594729453376] Iter[0] Batch [1500]#011Speed: 108836.98 samples/sec\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:39:09 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=1500 train rmse <loss>=1.11026836554\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:39:09 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=1500 train mse <loss>=1.23269584352\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:39:09 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=1500 train absolute_loss <loss>=0.871832301008\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:39:14 INFO 140594729453376] Iter[0] Batch [2000]#011Speed: 106964.23 samples/sec\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:39:14 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=2000 train rmse <loss>=1.09812509849\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:39:14 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=2000 train mse <loss>=1.20587873193\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:39:14 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=2000 train absolute_loss <loss>=0.864575144374\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:39:19 INFO 140594729453376] Iter[0] Batch [2500]#011Speed: 102404.56 samples/sec\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:39:19 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=2500 train rmse <loss>=1.09096759274\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:39:19 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=2500 train mse <loss>=1.19021028842\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:39:19 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=2500 train absolute_loss <loss>=0.860439650287\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[07/24/2020 14:39:24 INFO 140594729453376] Iter[0] Batch [3000]#011Speed: 96754.07 samples/sec\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:39:24 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=3000 train rmse <loss>=1.08619105479\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:39:24 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=3000 train mse <loss>=1.17981100752\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:39:24 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=3000 train absolute_loss <loss>=0.857865714338\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:39:29 INFO 140594729453376] Iter[0] Batch [3500]#011Speed: 96385.60 samples/sec\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:39:29 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=3500 train rmse <loss>=1.08259293534\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:39:29 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=3500 train mse <loss>=1.17200746365\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:39:29 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=3500 train absolute_loss <loss>=0.855759509595\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:39:35 INFO 140594729453376] Iter[0] Batch [4000]#011Speed: 94135.76 samples/sec\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:39:35 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=4000 train rmse <loss>=1.08000601309\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:39:35 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=4000 train mse <loss>=1.16641298831\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:39:35 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=4000 train absolute_loss <loss>=0.854332225858\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:39:40 INFO 140594729453376] Iter[0] Batch [4500]#011Speed: 86100.00 samples/sec\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:39:40 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=4500 train rmse <loss>=1.07790823027\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:39:40 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=4500 train mse <loss>=1.16188615289\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:39:40 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=4500 train absolute_loss <loss>=0.853185390348\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:39:46 INFO 140594729453376] Iter[0] Batch [5000]#011Speed: 90552.66 samples/sec\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:39:46 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=5000 train rmse <loss>=1.07636453041\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:39:46 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=5000 train mse <loss>=1.15856060233\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:39:46 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=5000 train absolute_loss <loss>=0.852403667521\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:39:51 INFO 140594729453376] Iter[0] Batch [5500]#011Speed: 90244.63 samples/sec\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:39:51 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=5500 train rmse <loss>=1.07509298472\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:39:51 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=5500 train mse <loss>=1.1558249258\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:39:51 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=5500 train absolute_loss <loss>=0.851762299777\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:39:57 INFO 140594729453376] Iter[0] Batch [6000]#011Speed: 88644.23 samples/sec\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:39:57 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=6000 train rmse <loss>=1.07393980862\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:39:57 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=6000 train mse <loss>=1.15334671254\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:39:57 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=6000 train absolute_loss <loss>=0.8511553742\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:40:03 INFO 140594729453376] Iter[0] Batch [6500]#011Speed: 88437.69 samples/sec\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:40:03 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=6500 train rmse <loss>=1.07313158183\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:40:03 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=6500 train mse <loss>=1.15161139193\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:40:03 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=6500 train absolute_loss <loss>=0.850742879504\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:40:08 INFO 140594729453376] Iter[0] Batch [7000]#011Speed: 88464.04 samples/sec\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:40:08 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=7000 train rmse <loss>=1.07241198476\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:40:08 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=7000 train mse <loss>=1.15006746505\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:40:08 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=7000 train absolute_loss <loss>=0.850397772905\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:40:14 INFO 140594729453376] Iter[0] Batch [7500]#011Speed: 88296.28 samples/sec\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:40:14 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=7500 train rmse <loss>=1.07163200076\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:40:14 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=7500 train mse <loss>=1.14839514506\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:40:14 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=7500 train absolute_loss <loss>=0.849983292633\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:40:20 INFO 140594729453376] Iter[0] Batch [8000]#011Speed: 88317.52 samples/sec\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:40:20 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=8000 train rmse <loss>=1.07102467998\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:40:20 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=8000 train mse <loss>=1.14709386513\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:40:20 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=8000 train absolute_loss <loss>=0.849665718444\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:40:26 INFO 140594729453376] Iter[0] Batch [8500]#011Speed: 82237.88 samples/sec\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:40:26 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=8500 train rmse <loss>=1.07057494812\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:40:26 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=8500 train mse <loss>=1.14613071953\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:40:26 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=8500 train absolute_loss <loss>=0.849443833878\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:40:32 INFO 140594729453376] Iter[0] Batch [9000]#011Speed: 85874.37 samples/sec\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:40:32 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=9000 train rmse <loss>=1.07012298148\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:40:32 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=9000 train mse <loss>=1.14516319549\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:40:32 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=9000 train absolute_loss <loss>=0.849226362062\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:40:37 INFO 140594729453376] Iter[0] Batch [9500]#011Speed: 87111.15 samples/sec\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:40:37 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=9500 train rmse <loss>=1.06973787621\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:40:37 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=9500 train mse <loss>=1.1443391238\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:40:37 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=9500 train absolute_loss <loss>=0.849075589006\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:40:43 INFO 140594729453376] Iter[0] Batch [10000]#011Speed: 87268.64 samples/sec\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:40:43 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=10000 train rmse <loss>=1.06934197143\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:40:43 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=10000 train mse <loss>=1.14349225186\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:40:43 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=10000 train absolute_loss <loss>=0.848831595728\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:40:49 INFO 140594729453376] Iter[0] Batch [10500]#011Speed: 85851.90 samples/sec\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:40:49 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=10500 train rmse <loss>=1.06892168102\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:40:49 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=10500 train mse <loss>=1.14259356016\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:40:49 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=10500 train absolute_loss <loss>=0.848591131184\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[07/24/2020 14:40:55 INFO 140594729453376] Iter[0] Batch [11000]#011Speed: 86153.02 samples/sec\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:40:55 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=11000 train rmse <loss>=1.06857943605\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:40:55 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=11000 train mse <loss>=1.14186201114\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:40:55 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=11000 train absolute_loss <loss>=0.84838495915\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:41:00 INFO 140594729453376] Iter[0] Batch [11500]#011Speed: 86476.72 samples/sec\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:41:00 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=11500 train rmse <loss>=1.06830448283\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:41:00 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=11500 train mse <loss>=1.14127446804\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:41:00 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=11500 train absolute_loss <loss>=0.848237396885\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:41:06 INFO 140594729453376] Iter[0] Batch [12000]#011Speed: 85732.81 samples/sec\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:41:06 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=12000 train rmse <loss>=1.06799403877\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:41:06 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=12000 train mse <loss>=1.14061126684\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:41:06 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=12000 train absolute_loss <loss>=0.848037224483\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:41:12 INFO 140594729453376] Iter[0] Batch [12500]#011Speed: 81555.36 samples/sec\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:41:12 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=12500 train rmse <loss>=1.06775355335\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:41:12 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=12500 train mse <loss>=1.1400976507\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:41:12 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=12500 train absolute_loss <loss>=0.847943775753\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:41:18 INFO 140594729453376] Iter[0] Batch [13000]#011Speed: 85401.11 samples/sec\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:41:18 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=13000 train rmse <loss>=1.06755626224\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:41:18 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=13000 train mse <loss>=1.13967637304\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:41:18 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=13000 train absolute_loss <loss>=0.84784876262\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:41:24 INFO 140594729453376] Iter[0] Batch [13500]#011Speed: 84427.66 samples/sec\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:41:24 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=13500 train rmse <loss>=1.06730875786\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:41:24 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=13500 train mse <loss>=1.1391479846\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:41:24 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=13500 train absolute_loss <loss>=0.84770364315\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:41:30 INFO 140594729453376] Iter[0] Batch [14000]#011Speed: 85027.77 samples/sec\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:41:30 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=14000 train rmse <loss>=1.06714667742\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:41:30 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=14000 train mse <loss>=1.13880203112\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:41:30 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=14000 train absolute_loss <loss>=0.847638299326\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:41:36 INFO 140594729453376] Iter[0] Batch [14500]#011Speed: 84714.72 samples/sec\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:41:36 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=14500 train rmse <loss>=1.06700445729\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:41:36 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=14500 train mse <loss>=1.13849851187\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:41:36 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=14500 train absolute_loss <loss>=0.84758745845\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:41:42 INFO 140594729453376] Iter[0] Batch [15000]#011Speed: 84053.80 samples/sec\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:41:42 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=15000 train rmse <loss>=1.06685015787\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:41:42 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=15000 train mse <loss>=1.13816925935\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:41:42 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=15000 train absolute_loss <loss>=0.847509359752\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:41:48 INFO 140594729453376] Iter[0] Batch [15500]#011Speed: 84417.57 samples/sec\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:41:48 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=15500 train rmse <loss>=1.06667400511\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:41:48 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=15500 train mse <loss>=1.13779343317\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:41:48 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=15500 train absolute_loss <loss>=0.847413928928\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:41:54 INFO 140594729453376] Iter[0] Batch [16000]#011Speed: 83362.00 samples/sec\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:41:54 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=16000 train rmse <loss>=1.06652768049\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:41:54 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=16000 train mse <loss>=1.13748129326\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:41:54 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=16000 train absolute_loss <loss>=0.847339255068\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:42:00 INFO 140594729453376] Iter[0] Batch [16500]#011Speed: 80298.43 samples/sec\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:42:00 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=16500 train rmse <loss>=1.06636123018\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:42:00 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=16500 train mse <loss>=1.13712627323\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:42:00 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=16500 train absolute_loss <loss>=0.847219315614\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:42:06 INFO 140594729453376] Iter[0] Batch [17000]#011Speed: 83539.09 samples/sec\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:42:06 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=17000 train rmse <loss>=1.06620642889\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:42:06 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=17000 train mse <loss>=1.13679614902\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:42:06 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=17000 train absolute_loss <loss>=0.847127254154\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:42:12 INFO 140594729453376] Iter[0] Batch [17500]#011Speed: 83034.94 samples/sec\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:42:12 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=17500 train rmse <loss>=1.06606965966\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:42:12 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=17500 train mse <loss>=1.13650451925\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:42:12 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=17500 train absolute_loss <loss>=0.847067581417\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:42:18 INFO 140594729453376] Iter[0] Batch [18000]#011Speed: 84134.67 samples/sec\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:42:18 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=18000 train rmse <loss>=1.06594543465\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:42:18 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=18000 train mse <loss>=1.13623966965\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:42:18 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=18000 train absolute_loss <loss>=0.84699235351\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:42:24 INFO 140594729453376] Iter[0] Batch [18500]#011Speed: 83475.66 samples/sec\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:42:24 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=18500 train rmse <loss>=1.06585632662\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:42:24 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=18500 train mse <loss>=1.136049709\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:42:24 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=18500 train absolute_loss <loss>=0.846949436568\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:42:30 INFO 140594729453376] Iter[0] Batch [19000]#011Speed: 83576.39 samples/sec\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:42:30 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=19000 train rmse <loss>=1.06581409231\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:42:30 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=19000 train mse <loss>=1.13595967937\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:42:30 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=19000 train absolute_loss <loss>=0.846948119754\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[07/24/2020 14:42:36 INFO 140594729453376] Iter[0] Batch [19500]#011Speed: 83664.09 samples/sec\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:42:36 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=19500 train rmse <loss>=1.06566293783\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:42:36 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=19500 train mse <loss>=1.13563749707\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:42:36 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=19500 train absolute_loss <loss>=0.846873935623\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:42:42 INFO 140594729453376] Iter[0] Batch [20000]#011Speed: 83646.31 samples/sec\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:42:42 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=20000 train rmse <loss>=1.06556133732\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:42:42 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=20000 train mse <loss>=1.13542096359\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:42:42 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=20000 train absolute_loss <loss>=0.846820755675\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:42:48 INFO 140594729453376] Iter[0] Batch [20500]#011Speed: 83306.94 samples/sec\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:42:48 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=20500 train rmse <loss>=1.06545699654\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:42:48 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=20500 train mse <loss>=1.13519861149\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:42:48 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=20500 train absolute_loss <loss>=0.846770741884\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:42:54 INFO 140594729453376] Iter[0] Batch [21000]#011Speed: 82747.92 samples/sec\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:42:54 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=21000 train rmse <loss>=1.06536969936\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:42:54 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=21000 train mse <loss>=1.13501259631\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:42:54 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=21000 train absolute_loss <loss>=0.84672358984\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:43:00 INFO 140594729453376] Iter[0] Batch [21500]#011Speed: 83060.04 samples/sec\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:43:00 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=21500 train rmse <loss>=1.06530993651\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:43:00 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=21500 train mse <loss>=1.13488526082\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:43:00 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=21500 train absolute_loss <loss>=0.846709298356\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:43:06 INFO 140594729453376] Iter[0] Batch [22000]#011Speed: 82809.53 samples/sec\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:43:06 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=22000 train rmse <loss>=1.06524731869\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:43:06 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=22000 train mse <loss>=1.13475184997\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:43:06 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=22000 train absolute_loss <loss>=0.846699567672\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:43:12 INFO 140594729453376] Iter[0] Batch [22500]#011Speed: 82572.88 samples/sec\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:43:12 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=22500 train rmse <loss>=1.06515719979\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:43:12 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=22500 train mse <loss>=1.13455986027\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:43:12 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=22500 train absolute_loss <loss>=0.846655413606\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:43:18 INFO 140594729453376] Iter[0] Batch [23000]#011Speed: 82837.83 samples/sec\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:43:18 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=23000 train rmse <loss>=1.06513652517\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:43:18 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=23000 train mse <loss>=1.13451581725\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:43:18 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=23000 train absolute_loss <loss>=0.846649889583\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:43:24 INFO 140594729453376] Iter[0] Batch [23500]#011Speed: 82241.44 samples/sec\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:43:24 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=23500 train rmse <loss>=1.06502184608\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:43:24 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=23500 train mse <loss>=1.13427153263\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:43:24 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, batch=23500 train absolute_loss <loss>=0.846550741711\u001b[0m\n",
      "\u001b[34m[2020-07-24 14:43:27.745] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 2, \"duration\": 272985, \"num_examples\": 23751, \"num_bytes\": 1605671392}\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:43:27 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, train rmse <loss>=1.0651903396\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:43:27 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, train mse <loss>=1.13463045958\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:43:27 INFO 140594729453376] #quality_metric: host=algo-1, epoch=0, train absolute_loss <loss>=0.846624377755\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:43:27 INFO 140594729453376] #quality_metric: host=algo-1, train rmse <loss>=1.0651903396\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:43:27 INFO 140594729453376] #quality_metric: host=algo-1, train mse <loss>=1.13463045958\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:43:27 INFO 140594729453376] #quality_metric: host=algo-1, train absolute_loss <loss>=0.846624377755\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"update.time\": {\"count\": 1, \"max\": 274043.90120506287, \"sum\": 274043.90120506287, \"min\": 274043.90120506287}}, \"EndTime\": 1595601807.745886, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1595601533.701412}\n",
      "\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:43:27 INFO 140594729453376] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 23751, \"sum\": 23751.0, \"min\": 23751}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 23751, \"sum\": 23751.0, \"min\": 23751}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 23750090, \"sum\": 23750090.0, \"min\": 23750090}, \"Total Batches Seen\": {\"count\": 1, \"max\": 23752, \"sum\": 23752.0, \"min\": 23752}, \"Total Records Seen\": {\"count\": 1, \"max\": 23751090, \"sum\": 23751090.0, \"min\": 23751090}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 23750090, \"sum\": 23750090.0, \"min\": 23750090}, \"Reset Count\": {\"count\": 1, \"max\": 2, \"sum\": 2.0, \"min\": 2}}, \"EndTime\": 1595601807.746076, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\", \"epoch\": 0}, \"StartTime\": 1595601533.701953}\n",
      "\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:43:27 INFO 140594729453376] #throughput_metric: host=algo-1, train throughput=86665.170806 records/second\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:43:27 WARNING 140594729453376] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:43:27 INFO 140594729453376] Pulling entire model from kvstore to finalize\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 46.23699188232422, \"sum\": 46.23699188232422, \"min\": 46.23699188232422}}, \"EndTime\": 1595601807.792573, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1595601807.745949}\n",
      "\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:43:28 INFO 140594729453376] Saved checkpoint to \"/tmp/tmpta6za7/state-0001.params\"\u001b[0m\n",
      "\u001b[34m[2020-07-24 14:43:28.347] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/test\", \"epoch\": 0, \"duration\": 274712, \"num_examples\": 1, \"num_bytes\": 67564}\u001b[0m\n",
      "\n",
      "2020-07-24 14:45:01 Uploading - Uploading generated training model\u001b[34m[2020-07-24 14:44:55.861] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/test\", \"epoch\": 1, \"duration\": 87514, \"num_examples\": 1251, \"num_bytes\": 84508164}\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1251, \"sum\": 1251.0, \"min\": 1251}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1251, \"sum\": 1251.0, \"min\": 1251}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1250005, \"sum\": 1250005.0, \"min\": 1250005}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1251, \"sum\": 1251.0, \"min\": 1251}, \"Total Records Seen\": {\"count\": 1, \"max\": 1250005, \"sum\": 1250005.0, \"min\": 1250005}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1250005, \"sum\": 1250005.0, \"min\": 1250005}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1595601895.862125, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"test_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1595601808.34704}\n",
      "\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:44:55 INFO 140594729453376] #test_score (algo-1) : ('rmse', 0.9584885878708627)\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:44:55 INFO 140594729453376] #test_score (algo-1) : ('mse', 0.9187003730786805)\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:44:55 INFO 140594729453376] #test_score (algo-1) : ('absolute_loss', 0.745087061570699)\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:44:55 INFO 140594729453376] #quality_metric: host=algo-1, test rmse <loss>=0.958488587871\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:44:55 INFO 140594729453376] #quality_metric: host=algo-1, test mse <loss>=0.918700373079\u001b[0m\n",
      "\u001b[34m[07/24/2020 14:44:55 INFO 140594729453376] #quality_metric: host=algo-1, test absolute_loss <loss>=0.745087061571\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 362277.7650356293, \"sum\": 362277.7650356293, \"min\": 362277.7650356293}, \"setuptime\": {\"count\": 1, \"max\": 41.14699363708496, \"sum\": 41.14699363708496, \"min\": 41.14699363708496}}, \"EndTime\": 1595601895.862819, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"factorization-machines\"}, \"StartTime\": 1595601807.79265}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-07-24 14:45:18 Completed - Training job completed\n",
      "Training seconds: 425\n",
      "Billable seconds: 425\n"
     ]
    }
   ],
   "source": [
    "fm = sagemaker.estimator.Estimator(container,\n",
    "                                   role=sagemaker.get_execution_role(),\n",
    "                                   instance_count=1, \n",
    "                                   instance_type='ml.c5.xlarge',\n",
    "                                   output_path=output_prefix,\n",
    "                                   volume_size=1\n",
    "                                   )\n",
    "\n",
    "fm.set_hyperparameters(feature_dim=num_features,\n",
    "                      predictor_type='regressor',\n",
    "                      num_factors=64,\n",
    "                      epochs=1)\n",
    "\n",
    "s3_train_data = sagemaker.TrainingInput(train_data, \n",
    "                                        distribution='FullyReplicated', \n",
    "                                        content_type='application/x-recordio-protobuf',\n",
    "                                        s3_data_type='S3Prefix',\n",
    "                                        input_mode='Pipe')\n",
    "\n",
    "s3_test_data = sagemaker.TrainingInput(test_data,\n",
    "                                             distribution='FullyReplicated', \n",
    "                                             content_type='application/x-recordio-protobuf', \n",
    "                                             s3_data_type='S3Prefix',\n",
    "                                             input_mode='Pipe')\n",
    "                                             \n",
    "fm.fit({'train': s3_train_data, 'test': s3_test_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    }
   ],
   "source": [
    "endpoint_name = 'fm-movielens-25m'\n",
    "fm_predictor = fm.deploy(endpoint_name=endpoint_name,\n",
    "                         instance_type='ml.t2.medium', initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def fm_serializer(data):\n",
    "    js = {'instances': []}\n",
    "    for row in data:\n",
    "        js['instances'].append({'features': row.tolist()})\n",
    "    return json.dumps(js)\n",
    "\n",
    "fm_predictor.content_type = 'application/json'\n",
    "fm_predictor.serializer = fm_serializer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = fm_predictor.predict(X_test[:3].toarray())\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
